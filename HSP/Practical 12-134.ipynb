{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical 12-134.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOonMkgT3oyKfomKX9FfSIq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEOd3WNtZNzZ","executionInfo":{"status":"ok","timestamp":1649490235727,"user_tz":-330,"elapsed":4535,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"0b2ccecb-106e-4828-e343-9c1055cfe54c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yahoo_fin in /usr/local/lib/python3.7/dist-packages (0.8.9.1)\n","Requirement already satisfied: requests-html in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (0.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (1.3.5)\n","Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (6.0.8)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser->yahoo_fin) (1.0.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (1.21.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2.10)\n","Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.0.2)\n","Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.1.11)\n","Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.22.0)\n","Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.4.3)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n","Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.19.0)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n","Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n","Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.63.0)\n","Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.7.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n","Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (1.1.0)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n"]}],"source":["# Name : Jinish Vaidya[19DCS153]\n","!pip install yahoo_fin"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from yahoo_fin import stock_info as si\n","# from yahoo_fin.stock_info import get_data\n","from collections import deque\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import random"],"metadata":{"id":"5DMxY5o8ZXA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set seed, so we can get the same results after rerunning several times\n","np.random.seed(314)\n","tf.random.set_seed(314)\n","random.seed(314)"],"metadata":{"id":"kTZDawXWZgyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import time\n","from tensorflow.keras.layers import LSTM\n","\n","# Window size or the sequence length\n","N_STEPS = 50\n","# Lookup step, 1 is the next day\n","LOOKUP_STEP = 15\n","\n","# whether to scale feature columns & output price as well\n","SCALE = True\n","scale_str = f\"sc-{int(SCALE)}\"\n","# whether to shuffle the dataset\n","SHUFFLE = True\n","shuffle_str = f\"sh-{int(SHUFFLE)}\"\n","# whether to split the training/testing set by date\n","SPLIT_BY_DATE = False\n","split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n","# test ratio size, 0.2 is 20%\n","TEST_SIZE = 0.2\n","# features to use\n","FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n","# date now\n","date_now = time.strftime(\"%Y-%m-%d\")\n","\n","### model parameters\n","\n","N_LAYERS = 2\n","# LSTM cell\n","CELL = LSTM\n","# 256 LSTM neurons\n","UNITS = 256\n","# 40% dropout\n","DROPOUT = 0.4\n","# whether to use bidirectional RNNs\n","BIDIRECTIONAL = False\n","\n","### training parameters\n","\n","# mean absolute error loss\n","# LOSS = \"mae\"\n","# huber loss\n","LOSS = \"huber_loss\"\n","OPTIMIZER = \"adam\"\n","BATCH_SIZE = 64\n","EPOCHS = 500\n","\n","# Amazon stock market\n","ticker = \"AMZN\"\n","ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n","# model name to save, making it as unique as possible based on parameters\n","model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n","{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n","if BIDIRECTIONAL:\n","    model_name += \"-b\""],"metadata":{"id":"Cds0_1pbZiM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def shuffle_in_unison(a, b):\n","    # shuffle two arrays in the same way\n","    state = np.random.get_state()\n","    np.random.shuffle(a)\n","    np.random.set_state(state)\n","    np.random.shuffle(b)\n","\n","\n","def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n","                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n","    # see if ticker is already a loaded stock from yahoo finance\n","    if isinstance(ticker, str):\n","        # load it from yahoo_fin library\n","        df = si.get_data(ticker)\n","    elif isinstance(ticker, pd.DataFrame):\n","        # already loaded, use it directly\n","        df = ticker\n","    else:\n","        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n","\n","    # this will contain all the elements we want to return from this function\n","    result = {}\n","    # we will also return the original dataframe itself\n","    result['df'] = df.copy()\n","\n","    # make sure that the passed feature_columns exist in the dataframe\n","    for col in feature_columns:\n","        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n","\n","    # add date as a column\n","    if \"date\" not in df.columns:\n","        df[\"date\"] = df.index\n","\n","    if scale:\n","        column_scaler = {}\n","        # scale the data (prices) from 0 to 1\n","        for column in feature_columns:\n","            scaler = preprocessing.MinMaxScaler()\n","            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n","            column_scaler[column] = scaler\n","\n","        # add the MinMaxScaler instances to the result returned\n","        result[\"column_scaler\"] = column_scaler\n","\n","    # add the target column (label) by shifting by `lookup_step`\n","    df['future'] = df['adjclose'].shift(-lookup_step)\n","\n","    # last `lookup_step` columns contains NaN in future column\n","    # get them before droping NaNs\n","    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n","    \n","    # drop NaNs\n","    df.dropna(inplace=True)\n","\n","    sequence_data = []\n","    sequences = deque(maxlen=n_steps)\n","\n","    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n","        sequences.append(entry)\n","        if len(sequences) == n_steps:\n","            sequence_data.append([np.array(sequences), target])\n","\n","    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n","    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n","    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n","    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n","    last_sequence = np.array(last_sequence).astype(np.float32)\n","    # add to result\n","    result['last_sequence'] = last_sequence\n","    \n","    # construct the X's and y's\n","    X, y = [], []\n","    for seq, target in sequence_data:\n","        X.append(seq)\n","        y.append(target)\n","\n","    # convert to numpy arrays\n","    X = np.array(X)\n","    y = np.array(y)\n","\n","    if split_by_date:\n","        # split the dataset into training & testing sets by date (not randomly splitting)\n","        train_samples = int((1 - test_size) * len(X))\n","        result[\"X_train\"] = X[:train_samples]\n","        result[\"y_train\"] = y[:train_samples]\n","        result[\"X_test\"]  = X[train_samples:]\n","        result[\"y_test\"]  = y[train_samples:]\n","        if shuffle:\n","            # shuffle the datasets for training (if shuffle parameter is set)\n","            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n","            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n","    else:    \n","        # split the dataset randomly\n","        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n","                                                                                test_size=test_size, shuffle=shuffle)\n","\n","    # get the list of test set dates\n","    dates = result[\"X_test\"][:, -1, -1]\n","    # retrieve test features from the original dataframe\n","    result[\"test_df\"] = result[\"df\"].loc[dates]\n","    # remove duplicated dates in the testing dataframe\n","    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n","    # remove dates from the training/testing sets & convert to float32\n","    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n","    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n","\n","    return result"],"metadata":{"id":"ciFof_swaSdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n","                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n","    model = Sequential()\n","    for i in range(n_layers):\n","        if i == 0:\n","            # first layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n","            else:\n","                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n","        elif i == n_layers - 1:\n","            # last layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=False)))\n","            else:\n","                model.add(cell(units, return_sequences=False))\n","        else:\n","            # hidden layers\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True)))\n","            else:\n","                model.add(cell(units, return_sequences=True))\n","        # add dropout after each layer\n","        model.add(Dropout(dropout))\n","    model.add(Dense(1, activation=\"linear\"))\n","    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n","    return model"],"metadata":{"id":"oY6TnB0yahyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create these folders if they does not exist\n","if not os.path.isdir(\"results\"):\n","    os.mkdir(\"results\")\n","\n","if not os.path.isdir(\"logs\"):\n","    os.mkdir(\"logs\")\n","\n","if not os.path.isdir(\"data\"):\n","    os.mkdir(\"data\")\n","\n","# load the data\n","data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n","                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n","                feature_columns=FEATURE_COLUMNS)\n","\n","# save the dataframe\n","data[\"df\"].to_csv(ticker_data_filename)\n","\n","# construct the model\n","model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n","                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"],"metadata":{"id":"fn0R3lM_akPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some tensorflow callbacks\n","checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n","tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n","# train the model and save the weights whenever we see \n","# a new optimal model using ModelCheckpoint\n","history = model.fit(data[\"X_train\"], data[\"y_train\"],\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n","                    callbacks=[checkpointer, tensorboard],\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7SxRFIRamS5","executionInfo":{"status":"ok","timestamp":1649488548917,"user_tz":-330,"elapsed":1588373,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"b4b1c9ee-ceb8-4290-885e-5c3c313b1dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","77/78 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0245\n","Epoch 1: val_loss improved from inf to 0.00025, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 20s 92ms/step - loss: 0.0016 - mean_absolute_error: 0.0244 - val_loss: 2.4608e-04 - val_mean_absolute_error: 0.0097\n","Epoch 2/500\n","78/78 [==============================] - ETA: 0s - loss: 5.2131e-04 - mean_absolute_error: 0.0156\n","Epoch 2: val_loss improved from 0.00025 to 0.00024, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 4s 54ms/step - loss: 5.2131e-04 - mean_absolute_error: 0.0156 - val_loss: 2.4405e-04 - val_mean_absolute_error: 0.0096\n","Epoch 3/500\n","78/78 [==============================] - ETA: 0s - loss: 5.9917e-04 - mean_absolute_error: 0.0165\n","Epoch 3: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 40ms/step - loss: 5.9917e-04 - mean_absolute_error: 0.0165 - val_loss: 3.3862e-04 - val_mean_absolute_error: 0.0130\n","Epoch 4/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.6266e-04 - mean_absolute_error: 0.0161\n","Epoch 4: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 39ms/step - loss: 5.5937e-04 - mean_absolute_error: 0.0160 - val_loss: 3.1625e-04 - val_mean_absolute_error: 0.0123\n","Epoch 5/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.3332e-04 - mean_absolute_error: 0.0161\n","Epoch 5: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 39ms/step - loss: 5.3573e-04 - mean_absolute_error: 0.0161 - val_loss: 3.6282e-04 - val_mean_absolute_error: 0.0134\n","Epoch 6/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.2981e-04 - mean_absolute_error: 0.0156\n","Epoch 6: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 38ms/step - loss: 5.2800e-04 - mean_absolute_error: 0.0156 - val_loss: 3.3533e-04 - val_mean_absolute_error: 0.0121\n","Epoch 7/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.1992e-04 - mean_absolute_error: 0.0159\n","Epoch 7: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 40ms/step - loss: 5.1849e-04 - mean_absolute_error: 0.0159 - val_loss: 3.3221e-04 - val_mean_absolute_error: 0.0139\n","Epoch 8/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.5073e-04 - mean_absolute_error: 0.0165\n","Epoch 8: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 39ms/step - loss: 5.4847e-04 - mean_absolute_error: 0.0164 - val_loss: 5.0317e-04 - val_mean_absolute_error: 0.0169\n","Epoch 9/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.5844e-04 - mean_absolute_error: 0.0161\n","Epoch 9: val_loss did not improve from 0.00024\n","78/78 [==============================] - 3s 39ms/step - loss: 5.5550e-04 - mean_absolute_error: 0.0161 - val_loss: 2.8645e-04 - val_mean_absolute_error: 0.0111\n","Epoch 10/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.8739e-04 - mean_absolute_error: 0.0153\n","Epoch 10: val_loss improved from 0.00024 to 0.00021, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 4.8682e-04 - mean_absolute_error: 0.0153 - val_loss: 2.0680e-04 - val_mean_absolute_error: 0.0100\n","Epoch 11/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.9631e-04 - mean_absolute_error: 0.0150\n","Epoch 11: val_loss did not improve from 0.00021\n","78/78 [==============================] - 3s 39ms/step - loss: 4.9649e-04 - mean_absolute_error: 0.0150 - val_loss: 2.1751e-04 - val_mean_absolute_error: 0.0103\n","Epoch 12/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.0282e-04 - mean_absolute_error: 0.0140\n","Epoch 12: val_loss did not improve from 0.00021\n","78/78 [==============================] - 3s 39ms/step - loss: 4.0119e-04 - mean_absolute_error: 0.0140 - val_loss: 3.1271e-04 - val_mean_absolute_error: 0.0136\n","Epoch 13/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.2692e-04 - mean_absolute_error: 0.0145\n","Epoch 13: val_loss did not improve from 0.00021\n","78/78 [==============================] - 3s 40ms/step - loss: 4.2586e-04 - mean_absolute_error: 0.0144 - val_loss: 2.3438e-04 - val_mean_absolute_error: 0.0098\n","Epoch 14/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.3407e-04 - mean_absolute_error: 0.0147\n","Epoch 14: val_loss did not improve from 0.00021\n","78/78 [==============================] - 3s 40ms/step - loss: 4.3324e-04 - mean_absolute_error: 0.0146 - val_loss: 2.9161e-04 - val_mean_absolute_error: 0.0112\n","Epoch 15/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.0804e-04 - mean_absolute_error: 0.0141\n","Epoch 15: val_loss did not improve from 0.00021\n","78/78 [==============================] - 3s 40ms/step - loss: 4.0714e-04 - mean_absolute_error: 0.0141 - val_loss: 2.8966e-04 - val_mean_absolute_error: 0.0116\n","Epoch 16/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.0909e-04 - mean_absolute_error: 0.0161\n","Epoch 16: val_loss improved from 0.00021 to 0.00020, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 5.0670e-04 - mean_absolute_error: 0.0160 - val_loss: 2.0065e-04 - val_mean_absolute_error: 0.0090\n","Epoch 17/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.3257e-04 - mean_absolute_error: 0.0144\n","Epoch 17: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 40ms/step - loss: 4.3423e-04 - mean_absolute_error: 0.0145 - val_loss: 3.6179e-04 - val_mean_absolute_error: 0.0124\n","Epoch 18/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.8798e-04 - mean_absolute_error: 0.0142\n","Epoch 18: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 3.8627e-04 - mean_absolute_error: 0.0141 - val_loss: 2.1746e-04 - val_mean_absolute_error: 0.0096\n","Epoch 19/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.1378e-04 - mean_absolute_error: 0.0145\n","Epoch 19: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 4.1371e-04 - mean_absolute_error: 0.0145 - val_loss: 3.2078e-04 - val_mean_absolute_error: 0.0133\n","Epoch 20/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.0830e-04 - mean_absolute_error: 0.0145\n","Epoch 20: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 4.0586e-04 - mean_absolute_error: 0.0145 - val_loss: 2.8886e-04 - val_mean_absolute_error: 0.0116\n","Epoch 21/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.0688e-04 - mean_absolute_error: 0.0144\n","Epoch 21: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 4.0793e-04 - mean_absolute_error: 0.0144 - val_loss: 8.6177e-04 - val_mean_absolute_error: 0.0218\n","Epoch 22/500\n","77/78 [============================>.] - ETA: 0s - loss: 5.8290e-04 - mean_absolute_error: 0.0178\n","Epoch 22: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 5.8207e-04 - mean_absolute_error: 0.0178 - val_loss: 4.3777e-04 - val_mean_absolute_error: 0.0136\n","Epoch 23/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.9940e-04 - mean_absolute_error: 0.0148\n","Epoch 23: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 4.0213e-04 - mean_absolute_error: 0.0148 - val_loss: 2.2466e-04 - val_mean_absolute_error: 0.0091\n","Epoch 24/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.7211e-04 - mean_absolute_error: 0.0146\n","Epoch 24: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 40ms/step - loss: 3.7188e-04 - mean_absolute_error: 0.0146 - val_loss: 2.2808e-04 - val_mean_absolute_error: 0.0091\n","Epoch 25/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6511e-04 - mean_absolute_error: 0.0141\n","Epoch 25: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 3.6370e-04 - mean_absolute_error: 0.0141 - val_loss: 2.3394e-04 - val_mean_absolute_error: 0.0100\n","Epoch 26/500\n","78/78 [==============================] - ETA: 0s - loss: 3.6435e-04 - mean_absolute_error: 0.0142\n","Epoch 26: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 41ms/step - loss: 3.6435e-04 - mean_absolute_error: 0.0142 - val_loss: 2.2111e-04 - val_mean_absolute_error: 0.0090\n","Epoch 27/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6362e-04 - mean_absolute_error: 0.0143\n","Epoch 27: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 39ms/step - loss: 3.6239e-04 - mean_absolute_error: 0.0143 - val_loss: 3.6119e-04 - val_mean_absolute_error: 0.0130\n","Epoch 28/500\n","77/78 [============================>.] - ETA: 0s - loss: 4.6290e-04 - mean_absolute_error: 0.0159\n","Epoch 28: val_loss did not improve from 0.00020\n","78/78 [==============================] - 3s 40ms/step - loss: 4.6167e-04 - mean_absolute_error: 0.0158 - val_loss: 2.1161e-04 - val_mean_absolute_error: 0.0091\n","Epoch 29/500\n","78/78 [==============================] - ETA: 0s - loss: 3.9385e-04 - mean_absolute_error: 0.0149\n","Epoch 29: val_loss did not improve from 0.00020\n","78/78 [==============================] - 4s 46ms/step - loss: 3.9385e-04 - mean_absolute_error: 0.0149 - val_loss: 2.4940e-04 - val_mean_absolute_error: 0.0095\n","Epoch 30/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.7473e-04 - mean_absolute_error: 0.0143\n","Epoch 30: val_loss improved from 0.00020 to 0.00019, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 43ms/step - loss: 3.7368e-04 - mean_absolute_error: 0.0143 - val_loss: 1.8520e-04 - val_mean_absolute_error: 0.0086\n","Epoch 31/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6723e-04 - mean_absolute_error: 0.0144\n","Epoch 31: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.6864e-04 - mean_absolute_error: 0.0144 - val_loss: 1.9099e-04 - val_mean_absolute_error: 0.0098\n","Epoch 32/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6170e-04 - mean_absolute_error: 0.0144\n","Epoch 32: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.6103e-04 - mean_absolute_error: 0.0144 - val_loss: 3.6513e-04 - val_mean_absolute_error: 0.0122\n","Epoch 33/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.8231e-04 - mean_absolute_error: 0.0147\n","Epoch 33: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.8221e-04 - mean_absolute_error: 0.0147 - val_loss: 2.0632e-04 - val_mean_absolute_error: 0.0097\n","Epoch 34/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1564e-04 - mean_absolute_error: 0.0141\n","Epoch 34: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1404e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8821e-04 - val_mean_absolute_error: 0.0090\n","Epoch 35/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4944e-04 - mean_absolute_error: 0.0142\n","Epoch 35: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.4853e-04 - mean_absolute_error: 0.0142 - val_loss: 1.8782e-04 - val_mean_absolute_error: 0.0090\n","Epoch 36/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.5269e-04 - mean_absolute_error: 0.0142\n","Epoch 36: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 40ms/step - loss: 3.5085e-04 - mean_absolute_error: 0.0141 - val_loss: 2.4855e-04 - val_mean_absolute_error: 0.0120\n","Epoch 37/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6945e-04 - mean_absolute_error: 0.0147\n","Epoch 37: val_loss did not improve from 0.00019\n","78/78 [==============================] - 3s 39ms/step - loss: 3.7591e-04 - mean_absolute_error: 0.0148 - val_loss: 3.1494e-04 - val_mean_absolute_error: 0.0133\n","Epoch 38/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4917e-04 - mean_absolute_error: 0.0144\n","Epoch 38: val_loss improved from 0.00019 to 0.00018, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 41ms/step - loss: 3.4803e-04 - mean_absolute_error: 0.0144 - val_loss: 1.8381e-04 - val_mean_absolute_error: 0.0086\n","Epoch 39/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.3951e-04 - mean_absolute_error: 0.0141\n","Epoch 39: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 40ms/step - loss: 3.3924e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8446e-04 - val_mean_absolute_error: 0.0088\n","Epoch 40/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4565e-04 - mean_absolute_error: 0.0146\n","Epoch 40: val_loss improved from 0.00018 to 0.00018, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 41ms/step - loss: 3.4535e-04 - mean_absolute_error: 0.0146 - val_loss: 1.8085e-04 - val_mean_absolute_error: 0.0093\n","Epoch 41/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4201e-04 - mean_absolute_error: 0.0144\n","Epoch 41: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 39ms/step - loss: 3.4142e-04 - mean_absolute_error: 0.0144 - val_loss: 2.6518e-04 - val_mean_absolute_error: 0.0107\n","Epoch 42/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.3109e-04 - mean_absolute_error: 0.0142\n","Epoch 42: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 39ms/step - loss: 3.3090e-04 - mean_absolute_error: 0.0142 - val_loss: 1.8892e-04 - val_mean_absolute_error: 0.0084\n","Epoch 43/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1348e-04 - mean_absolute_error: 0.0139\n","Epoch 43: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1394e-04 - mean_absolute_error: 0.0139 - val_loss: 2.1177e-04 - val_mean_absolute_error: 0.0093\n","Epoch 44/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1918e-04 - mean_absolute_error: 0.0142\n","Epoch 44: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1798e-04 - mean_absolute_error: 0.0142 - val_loss: 3.0569e-04 - val_mean_absolute_error: 0.0128\n","Epoch 45/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.6035e-04 - mean_absolute_error: 0.0149\n","Epoch 45: val_loss did not improve from 0.00018\n","78/78 [==============================] - 3s 39ms/step - loss: 3.5931e-04 - mean_absolute_error: 0.0149 - val_loss: 2.0160e-04 - val_mean_absolute_error: 0.0093\n","Epoch 46/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2828e-04 - mean_absolute_error: 0.0143\n","Epoch 46: val_loss improved from 0.00018 to 0.00017, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.2746e-04 - mean_absolute_error: 0.0143 - val_loss: 1.7468e-04 - val_mean_absolute_error: 0.0087\n","Epoch 47/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1164e-04 - mean_absolute_error: 0.0139\n","Epoch 47: val_loss improved from 0.00017 to 0.00017, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1012e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6556e-04 - val_mean_absolute_error: 0.0086\n","Epoch 48/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2226e-04 - mean_absolute_error: 0.0141\n","Epoch 48: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.2259e-04 - mean_absolute_error: 0.0141 - val_loss: 1.6595e-04 - val_mean_absolute_error: 0.0081\n","Epoch 49/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2910e-04 - mean_absolute_error: 0.0143\n","Epoch 49: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 41ms/step - loss: 3.2817e-04 - mean_absolute_error: 0.0143 - val_loss: 1.9804e-04 - val_mean_absolute_error: 0.0102\n","Epoch 50/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2331e-04 - mean_absolute_error: 0.0141\n","Epoch 50: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.2715e-04 - mean_absolute_error: 0.0141 - val_loss: 1.9980e-04 - val_mean_absolute_error: 0.0093\n","Epoch 51/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.3807e-04 - mean_absolute_error: 0.0145\n","Epoch 51: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.3795e-04 - mean_absolute_error: 0.0145 - val_loss: 1.7894e-04 - val_mean_absolute_error: 0.0084\n","Epoch 52/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4243e-04 - mean_absolute_error: 0.0144\n","Epoch 52: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.4202e-04 - mean_absolute_error: 0.0144 - val_loss: 2.3480e-04 - val_mean_absolute_error: 0.0110\n","Epoch 53/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4769e-04 - mean_absolute_error: 0.0146\n","Epoch 53: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 41ms/step - loss: 3.4645e-04 - mean_absolute_error: 0.0146 - val_loss: 1.7104e-04 - val_mean_absolute_error: 0.0086\n","Epoch 54/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1923e-04 - mean_absolute_error: 0.0143\n","Epoch 54: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1909e-04 - mean_absolute_error: 0.0143 - val_loss: 1.8980e-04 - val_mean_absolute_error: 0.0087\n","Epoch 55/500\n","78/78 [==============================] - ETA: 0s - loss: 3.2309e-04 - mean_absolute_error: 0.0143\n","Epoch 55: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.2309e-04 - mean_absolute_error: 0.0143 - val_loss: 1.7430e-04 - val_mean_absolute_error: 0.0082\n","Epoch 56/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.7008e-04 - mean_absolute_error: 0.0152\n","Epoch 56: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.6964e-04 - mean_absolute_error: 0.0152 - val_loss: 1.9337e-04 - val_mean_absolute_error: 0.0088\n","Epoch 57/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1279e-04 - mean_absolute_error: 0.0141\n","Epoch 57: val_loss did not improve from 0.00017\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1198e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8104e-04 - val_mean_absolute_error: 0.0088\n","Epoch 58/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1709e-04 - mean_absolute_error: 0.0140\n","Epoch 58: val_loss improved from 0.00017 to 0.00016, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1757e-04 - mean_absolute_error: 0.0140 - val_loss: 1.6473e-04 - val_mean_absolute_error: 0.0084\n","Epoch 59/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.4110e-04 - mean_absolute_error: 0.0148\n","Epoch 59: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.3952e-04 - mean_absolute_error: 0.0147 - val_loss: 2.2992e-04 - val_mean_absolute_error: 0.0104\n","Epoch 60/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1214e-04 - mean_absolute_error: 0.0143\n","Epoch 60: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1136e-04 - mean_absolute_error: 0.0143 - val_loss: 2.1941e-04 - val_mean_absolute_error: 0.0105\n","Epoch 61/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2315e-04 - mean_absolute_error: 0.0142\n","Epoch 61: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.2143e-04 - mean_absolute_error: 0.0142 - val_loss: 1.9886e-04 - val_mean_absolute_error: 0.0109\n","Epoch 62/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0646e-04 - mean_absolute_error: 0.0142\n","Epoch 62: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0929e-04 - mean_absolute_error: 0.0142 - val_loss: 1.9288e-04 - val_mean_absolute_error: 0.0093\n","Epoch 63/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9007e-04 - mean_absolute_error: 0.0136\n","Epoch 63: val_loss improved from 0.00016 to 0.00016, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9368e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5727e-04 - val_mean_absolute_error: 0.0085\n","Epoch 64/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8436e-04 - mean_absolute_error: 0.0136\n","Epoch 64: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8302e-04 - mean_absolute_error: 0.0136 - val_loss: 1.9117e-04 - val_mean_absolute_error: 0.0087\n","Epoch 65/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0555e-04 - mean_absolute_error: 0.0139\n","Epoch 65: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0610e-04 - mean_absolute_error: 0.0139 - val_loss: 1.7004e-04 - val_mean_absolute_error: 0.0088\n","Epoch 66/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9992e-04 - mean_absolute_error: 0.0138\n","Epoch 66: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9850e-04 - mean_absolute_error: 0.0138 - val_loss: 2.3261e-04 - val_mean_absolute_error: 0.0097\n","Epoch 67/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1398e-04 - mean_absolute_error: 0.0142\n","Epoch 67: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1249e-04 - mean_absolute_error: 0.0142 - val_loss: 1.9390e-04 - val_mean_absolute_error: 0.0092\n","Epoch 68/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0337e-04 - mean_absolute_error: 0.0141\n","Epoch 68: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0193e-04 - mean_absolute_error: 0.0141 - val_loss: 2.1858e-04 - val_mean_absolute_error: 0.0100\n","Epoch 69/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9537e-04 - mean_absolute_error: 0.0140\n","Epoch 69: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9633e-04 - mean_absolute_error: 0.0141 - val_loss: 1.6487e-04 - val_mean_absolute_error: 0.0080\n","Epoch 70/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8747e-04 - mean_absolute_error: 0.0138\n","Epoch 70: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8829e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6290e-04 - val_mean_absolute_error: 0.0082\n","Epoch 71/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1399e-04 - mean_absolute_error: 0.0146\n","Epoch 71: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1316e-04 - mean_absolute_error: 0.0146 - val_loss: 1.7879e-04 - val_mean_absolute_error: 0.0097\n","Epoch 72/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1974e-04 - mean_absolute_error: 0.0144\n","Epoch 72: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1942e-04 - mean_absolute_error: 0.0144 - val_loss: 1.7533e-04 - val_mean_absolute_error: 0.0090\n","Epoch 73/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8943e-04 - mean_absolute_error: 0.0138\n","Epoch 73: val_loss did not improve from 0.00016\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8974e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6151e-04 - val_mean_absolute_error: 0.0083\n","Epoch 74/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0938e-04 - mean_absolute_error: 0.0141\n","Epoch 74: val_loss improved from 0.00016 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1043e-04 - mean_absolute_error: 0.0142 - val_loss: 1.5095e-04 - val_mean_absolute_error: 0.0081\n","Epoch 75/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9943e-04 - mean_absolute_error: 0.0141\n","Epoch 75: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0014e-04 - mean_absolute_error: 0.0141 - val_loss: 2.1047e-04 - val_mean_absolute_error: 0.0093\n","Epoch 76/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0960e-04 - mean_absolute_error: 0.0143\n","Epoch 76: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0935e-04 - mean_absolute_error: 0.0142 - val_loss: 1.6351e-04 - val_mean_absolute_error: 0.0083\n","Epoch 77/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0278e-04 - mean_absolute_error: 0.0142\n","Epoch 77: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0748e-04 - mean_absolute_error: 0.0142 - val_loss: 1.7238e-04 - val_mean_absolute_error: 0.0090\n","Epoch 78/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1877e-04 - mean_absolute_error: 0.0142\n","Epoch 78: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1776e-04 - mean_absolute_error: 0.0142 - val_loss: 2.1332e-04 - val_mean_absolute_error: 0.0105\n","Epoch 79/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1204e-04 - mean_absolute_error: 0.0143\n","Epoch 79: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1198e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6027e-04 - val_mean_absolute_error: 0.0106\n","Epoch 80/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9828e-04 - mean_absolute_error: 0.0141\n","Epoch 80: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9825e-04 - mean_absolute_error: 0.0141 - val_loss: 2.2589e-04 - val_mean_absolute_error: 0.0105\n","Epoch 81/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1639e-04 - mean_absolute_error: 0.0145\n","Epoch 81: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 38ms/step - loss: 3.1810e-04 - mean_absolute_error: 0.0146 - val_loss: 1.7988e-04 - val_mean_absolute_error: 0.0092\n","Epoch 82/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1688e-04 - mean_absolute_error: 0.0145\n","Epoch 82: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1544e-04 - mean_absolute_error: 0.0145 - val_loss: 1.5716e-04 - val_mean_absolute_error: 0.0089\n","Epoch 83/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9716e-04 - mean_absolute_error: 0.0145\n","Epoch 83: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9572e-04 - mean_absolute_error: 0.0145 - val_loss: 1.5551e-04 - val_mean_absolute_error: 0.0092\n","Epoch 84/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9660e-04 - mean_absolute_error: 0.0140\n","Epoch 84: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9728e-04 - mean_absolute_error: 0.0140 - val_loss: 1.5379e-04 - val_mean_absolute_error: 0.0083\n","Epoch 85/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0967e-04 - mean_absolute_error: 0.0144\n","Epoch 85: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1089e-04 - mean_absolute_error: 0.0144 - val_loss: 1.6993e-04 - val_mean_absolute_error: 0.0082\n","Epoch 86/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9004e-04 - mean_absolute_error: 0.0138\n","Epoch 86: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9244e-04 - mean_absolute_error: 0.0138 - val_loss: 1.7299e-04 - val_mean_absolute_error: 0.0088\n","Epoch 87/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8042e-04 - mean_absolute_error: 0.0139\n","Epoch 87: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8278e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6437e-04 - val_mean_absolute_error: 0.0083\n","Epoch 88/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0672e-04 - mean_absolute_error: 0.0142\n","Epoch 88: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0652e-04 - mean_absolute_error: 0.0142 - val_loss: 1.5580e-04 - val_mean_absolute_error: 0.0085\n","Epoch 89/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1124e-04 - mean_absolute_error: 0.0144\n","Epoch 89: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0973e-04 - mean_absolute_error: 0.0144 - val_loss: 1.5946e-04 - val_mean_absolute_error: 0.0087\n","Epoch 90/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9437e-04 - mean_absolute_error: 0.0140\n","Epoch 90: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9384e-04 - mean_absolute_error: 0.0140 - val_loss: 1.8324e-04 - val_mean_absolute_error: 0.0094\n","Epoch 91/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8316e-04 - mean_absolute_error: 0.0137\n","Epoch 91: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8549e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6605e-04 - val_mean_absolute_error: 0.0083\n","Epoch 92/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9149e-04 - mean_absolute_error: 0.0140\n","Epoch 92: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9143e-04 - mean_absolute_error: 0.0140 - val_loss: 1.5445e-04 - val_mean_absolute_error: 0.0086\n","Epoch 93/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1370e-04 - mean_absolute_error: 0.0144\n","Epoch 93: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1497e-04 - mean_absolute_error: 0.0145 - val_loss: 2.0417e-04 - val_mean_absolute_error: 0.0105\n","Epoch 94/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1037e-04 - mean_absolute_error: 0.0142\n","Epoch 94: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1146e-04 - mean_absolute_error: 0.0143 - val_loss: 1.5300e-04 - val_mean_absolute_error: 0.0089\n","Epoch 95/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8287e-04 - mean_absolute_error: 0.0138\n","Epoch 95: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8284e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6987e-04 - val_mean_absolute_error: 0.0091\n","Epoch 96/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0117e-04 - mean_absolute_error: 0.0141\n","Epoch 96: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0132e-04 - mean_absolute_error: 0.0141 - val_loss: 1.5565e-04 - val_mean_absolute_error: 0.0090\n","Epoch 97/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1039e-04 - mean_absolute_error: 0.0145\n","Epoch 97: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1292e-04 - mean_absolute_error: 0.0145 - val_loss: 2.0920e-04 - val_mean_absolute_error: 0.0103\n","Epoch 98/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1774e-04 - mean_absolute_error: 0.0144\n","Epoch 98: val_loss improved from 0.00015 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1921e-04 - mean_absolute_error: 0.0144 - val_loss: 1.5014e-04 - val_mean_absolute_error: 0.0086\n","Epoch 99/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0350e-04 - mean_absolute_error: 0.0142\n","Epoch 99: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0235e-04 - mean_absolute_error: 0.0142 - val_loss: 1.7305e-04 - val_mean_absolute_error: 0.0091\n","Epoch 100/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0225e-04 - mean_absolute_error: 0.0141\n","Epoch 100: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0071e-04 - mean_absolute_error: 0.0141 - val_loss: 1.7833e-04 - val_mean_absolute_error: 0.0088\n","Epoch 101/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1488e-04 - mean_absolute_error: 0.0140\n","Epoch 101: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1337e-04 - mean_absolute_error: 0.0140 - val_loss: 1.7222e-04 - val_mean_absolute_error: 0.0095\n","Epoch 102/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9804e-04 - mean_absolute_error: 0.0142\n","Epoch 102: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9829e-04 - mean_absolute_error: 0.0142 - val_loss: 1.6073e-04 - val_mean_absolute_error: 0.0092\n","Epoch 103/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1416e-04 - mean_absolute_error: 0.0143\n","Epoch 103: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1282e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6186e-04 - val_mean_absolute_error: 0.0086\n","Epoch 104/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1679e-04 - mean_absolute_error: 0.0146\n","Epoch 104: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1531e-04 - mean_absolute_error: 0.0146 - val_loss: 1.6324e-04 - val_mean_absolute_error: 0.0092\n","Epoch 105/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0613e-04 - mean_absolute_error: 0.0143\n","Epoch 105: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0547e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6169e-04 - val_mean_absolute_error: 0.0089\n","Epoch 106/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6398e-04 - mean_absolute_error: 0.0131\n","Epoch 106: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6358e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5287e-04 - val_mean_absolute_error: 0.0085\n","Epoch 107/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9447e-04 - mean_absolute_error: 0.0139\n","Epoch 107: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9931e-04 - mean_absolute_error: 0.0140 - val_loss: 1.6963e-04 - val_mean_absolute_error: 0.0084\n","Epoch 108/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8625e-04 - mean_absolute_error: 0.0141\n","Epoch 108: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8551e-04 - mean_absolute_error: 0.0141 - val_loss: 2.2413e-04 - val_mean_absolute_error: 0.0135\n","Epoch 109/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.3854e-04 - mean_absolute_error: 0.0151\n","Epoch 109: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.3943e-04 - mean_absolute_error: 0.0151 - val_loss: 1.7614e-04 - val_mean_absolute_error: 0.0090\n","Epoch 110/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8229e-04 - mean_absolute_error: 0.0138\n","Epoch 110: val_loss improved from 0.00015 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8235e-04 - mean_absolute_error: 0.0138 - val_loss: 1.4960e-04 - val_mean_absolute_error: 0.0079\n","Epoch 111/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7476e-04 - mean_absolute_error: 0.0136\n","Epoch 111: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7495e-04 - mean_absolute_error: 0.0136 - val_loss: 1.7040e-04 - val_mean_absolute_error: 0.0089\n","Epoch 112/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9058e-04 - mean_absolute_error: 0.0141\n","Epoch 112: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9136e-04 - mean_absolute_error: 0.0141 - val_loss: 1.5731e-04 - val_mean_absolute_error: 0.0083\n","Epoch 113/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7962e-04 - mean_absolute_error: 0.0140\n","Epoch 113: val_loss improved from 0.00015 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8046e-04 - mean_absolute_error: 0.0140 - val_loss: 1.4849e-04 - val_mean_absolute_error: 0.0082\n","Epoch 114/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0605e-04 - mean_absolute_error: 0.0142\n","Epoch 114: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0559e-04 - mean_absolute_error: 0.0141 - val_loss: 1.5630e-04 - val_mean_absolute_error: 0.0083\n","Epoch 115/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2312e-04 - mean_absolute_error: 0.0145\n","Epoch 115: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.2292e-04 - mean_absolute_error: 0.0144 - val_loss: 1.6185e-04 - val_mean_absolute_error: 0.0086\n","Epoch 116/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9955e-04 - mean_absolute_error: 0.0143\n","Epoch 116: val_loss improved from 0.00015 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0005e-04 - mean_absolute_error: 0.0142 - val_loss: 1.4756e-04 - val_mean_absolute_error: 0.0081\n","Epoch 117/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.2070e-04 - mean_absolute_error: 0.0143\n","Epoch 117: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.1950e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6073e-04 - val_mean_absolute_error: 0.0101\n","Epoch 118/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9090e-04 - mean_absolute_error: 0.0141\n","Epoch 118: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9095e-04 - mean_absolute_error: 0.0141 - val_loss: 2.0842e-04 - val_mean_absolute_error: 0.0111\n","Epoch 119/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9962e-04 - mean_absolute_error: 0.0139\n","Epoch 119: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9878e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5801e-04 - val_mean_absolute_error: 0.0083\n","Epoch 120/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8682e-04 - mean_absolute_error: 0.0137\n","Epoch 120: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8751e-04 - mean_absolute_error: 0.0137 - val_loss: 2.0832e-04 - val_mean_absolute_error: 0.0106\n","Epoch 121/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8537e-04 - mean_absolute_error: 0.0137\n","Epoch 121: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8681e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4905e-04 - val_mean_absolute_error: 0.0081\n","Epoch 122/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7633e-04 - mean_absolute_error: 0.0139\n","Epoch 122: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7608e-04 - mean_absolute_error: 0.0139 - val_loss: 1.7293e-04 - val_mean_absolute_error: 0.0100\n","Epoch 123/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8667e-04 - mean_absolute_error: 0.0138\n","Epoch 123: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8654e-04 - mean_absolute_error: 0.0138 - val_loss: 2.3004e-04 - val_mean_absolute_error: 0.0131\n","Epoch 124/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1748e-04 - mean_absolute_error: 0.0148\n","Epoch 124: val_loss improved from 0.00015 to 0.00015, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 3.1737e-04 - mean_absolute_error: 0.0148 - val_loss: 1.4590e-04 - val_mean_absolute_error: 0.0089\n","Epoch 125/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9471e-04 - mean_absolute_error: 0.0139\n","Epoch 125: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.9966e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6347e-04 - val_mean_absolute_error: 0.0097\n","Epoch 126/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6972e-04 - mean_absolute_error: 0.0135\n","Epoch 126: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6927e-04 - mean_absolute_error: 0.0135 - val_loss: 1.7007e-04 - val_mean_absolute_error: 0.0089\n","Epoch 127/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7202e-04 - mean_absolute_error: 0.0136\n","Epoch 127: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7087e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5294e-04 - val_mean_absolute_error: 0.0090\n","Epoch 128/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0306e-04 - mean_absolute_error: 0.0140\n","Epoch 128: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0190e-04 - mean_absolute_error: 0.0140 - val_loss: 1.6626e-04 - val_mean_absolute_error: 0.0084\n","Epoch 129/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7090e-04 - mean_absolute_error: 0.0135\n","Epoch 129: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7050e-04 - mean_absolute_error: 0.0135 - val_loss: 1.7118e-04 - val_mean_absolute_error: 0.0096\n","Epoch 130/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9373e-04 - mean_absolute_error: 0.0140\n","Epoch 130: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9724e-04 - mean_absolute_error: 0.0140 - val_loss: 1.5649e-04 - val_mean_absolute_error: 0.0088\n","Epoch 131/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9055e-04 - mean_absolute_error: 0.0137\n","Epoch 131: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8910e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5303e-04 - val_mean_absolute_error: 0.0088\n","Epoch 132/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9282e-04 - mean_absolute_error: 0.0139\n","Epoch 132: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9177e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6472e-04 - val_mean_absolute_error: 0.0104\n","Epoch 133/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8838e-04 - mean_absolute_error: 0.0140\n","Epoch 133: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8871e-04 - mean_absolute_error: 0.0140 - val_loss: 1.5199e-04 - val_mean_absolute_error: 0.0089\n","Epoch 134/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8223e-04 - mean_absolute_error: 0.0136\n","Epoch 134: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8154e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5422e-04 - val_mean_absolute_error: 0.0081\n","Epoch 135/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0426e-04 - mean_absolute_error: 0.0139\n","Epoch 135: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0469e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5922e-04 - val_mean_absolute_error: 0.0092\n","Epoch 136/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1589e-04 - mean_absolute_error: 0.0144\n","Epoch 136: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 38ms/step - loss: 3.1502e-04 - mean_absolute_error: 0.0144 - val_loss: 1.7167e-04 - val_mean_absolute_error: 0.0091\n","Epoch 137/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8505e-04 - mean_absolute_error: 0.0138\n","Epoch 137: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8414e-04 - mean_absolute_error: 0.0138 - val_loss: 1.8678e-04 - val_mean_absolute_error: 0.0089\n","Epoch 138/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8946e-04 - mean_absolute_error: 0.0137\n","Epoch 138: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8876e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5501e-04 - val_mean_absolute_error: 0.0087\n","Epoch 139/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9844e-04 - mean_absolute_error: 0.0142\n","Epoch 139: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9779e-04 - mean_absolute_error: 0.0142 - val_loss: 1.4839e-04 - val_mean_absolute_error: 0.0084\n","Epoch 140/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8970e-04 - mean_absolute_error: 0.0140\n","Epoch 140: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8792e-04 - mean_absolute_error: 0.0139 - val_loss: 1.9250e-04 - val_mean_absolute_error: 0.0106\n","Epoch 141/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8699e-04 - mean_absolute_error: 0.0136\n","Epoch 141: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8555e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5820e-04 - val_mean_absolute_error: 0.0082\n","Epoch 142/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7618e-04 - mean_absolute_error: 0.0137\n","Epoch 142: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7687e-04 - mean_absolute_error: 0.0137 - val_loss: 1.7016e-04 - val_mean_absolute_error: 0.0092\n","Epoch 143/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0174e-04 - mean_absolute_error: 0.0137\n","Epoch 143: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 42ms/step - loss: 3.0384e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6913e-04 - val_mean_absolute_error: 0.0087\n","Epoch 144/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7589e-04 - mean_absolute_error: 0.0136\n","Epoch 144: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7596e-04 - mean_absolute_error: 0.0136 - val_loss: 1.8681e-04 - val_mean_absolute_error: 0.0093\n","Epoch 145/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8198e-04 - mean_absolute_error: 0.0135\n","Epoch 145: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8101e-04 - mean_absolute_error: 0.0135 - val_loss: 2.0377e-04 - val_mean_absolute_error: 0.0098\n","Epoch 146/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8089e-04 - mean_absolute_error: 0.0135\n","Epoch 146: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7945e-04 - mean_absolute_error: 0.0134 - val_loss: 1.7870e-04 - val_mean_absolute_error: 0.0090\n","Epoch 147/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8946e-04 - mean_absolute_error: 0.0136\n","Epoch 147: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8872e-04 - mean_absolute_error: 0.0136 - val_loss: 1.6782e-04 - val_mean_absolute_error: 0.0083\n","Epoch 148/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7523e-04 - mean_absolute_error: 0.0134\n","Epoch 148: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7544e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4801e-04 - val_mean_absolute_error: 0.0094\n","Epoch 149/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9377e-04 - mean_absolute_error: 0.0140\n","Epoch 149: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9310e-04 - mean_absolute_error: 0.0140 - val_loss: 1.4829e-04 - val_mean_absolute_error: 0.0085\n","Epoch 150/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0820e-04 - mean_absolute_error: 0.0142\n","Epoch 150: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0936e-04 - mean_absolute_error: 0.0142 - val_loss: 1.5108e-04 - val_mean_absolute_error: 0.0086\n","Epoch 151/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9599e-04 - mean_absolute_error: 0.0139\n","Epoch 151: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9931e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5766e-04 - val_mean_absolute_error: 0.0086\n","Epoch 152/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8373e-04 - mean_absolute_error: 0.0135\n","Epoch 152: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8231e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5946e-04 - val_mean_absolute_error: 0.0085\n","Epoch 153/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7483e-04 - mean_absolute_error: 0.0136\n","Epoch 153: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7461e-04 - mean_absolute_error: 0.0136 - val_loss: 1.7182e-04 - val_mean_absolute_error: 0.0088\n","Epoch 154/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9462e-04 - mean_absolute_error: 0.0137\n","Epoch 154: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9324e-04 - mean_absolute_error: 0.0137 - val_loss: 1.6165e-04 - val_mean_absolute_error: 0.0087\n","Epoch 155/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9366e-04 - mean_absolute_error: 0.0139\n","Epoch 155: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9384e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5397e-04 - val_mean_absolute_error: 0.0088\n","Epoch 156/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.1450e-04 - mean_absolute_error: 0.0143\n","Epoch 156: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 3.1380e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6634e-04 - val_mean_absolute_error: 0.0092\n","Epoch 157/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9931e-04 - mean_absolute_error: 0.0139\n","Epoch 157: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9960e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4937e-04 - val_mean_absolute_error: 0.0084\n","Epoch 158/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6714e-04 - mean_absolute_error: 0.0134\n","Epoch 158: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6731e-04 - mean_absolute_error: 0.0134 - val_loss: 2.5873e-04 - val_mean_absolute_error: 0.0124\n","Epoch 159/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7988e-04 - mean_absolute_error: 0.0136\n","Epoch 159: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7849e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4984e-04 - val_mean_absolute_error: 0.0080\n","Epoch 160/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8747e-04 - mean_absolute_error: 0.0137\n","Epoch 160: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8772e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5382e-04 - val_mean_absolute_error: 0.0089\n","Epoch 161/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9599e-04 - mean_absolute_error: 0.0140\n","Epoch 161: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9456e-04 - mean_absolute_error: 0.0139 - val_loss: 1.7041e-04 - val_mean_absolute_error: 0.0093\n","Epoch 162/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9521e-04 - mean_absolute_error: 0.0138\n","Epoch 162: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9510e-04 - mean_absolute_error: 0.0138 - val_loss: 1.4660e-04 - val_mean_absolute_error: 0.0080\n","Epoch 163/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8212e-04 - mean_absolute_error: 0.0135\n","Epoch 163: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8227e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5660e-04 - val_mean_absolute_error: 0.0088\n","Epoch 164/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9296e-04 - mean_absolute_error: 0.0137\n","Epoch 164: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9214e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5036e-04 - val_mean_absolute_error: 0.0084\n","Epoch 165/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7282e-04 - mean_absolute_error: 0.0136\n","Epoch 165: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7177e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5737e-04 - val_mean_absolute_error: 0.0082\n","Epoch 166/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7855e-04 - mean_absolute_error: 0.0134\n","Epoch 166: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7848e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6121e-04 - val_mean_absolute_error: 0.0083\n","Epoch 167/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6049e-04 - mean_absolute_error: 0.0131\n","Epoch 167: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6197e-04 - mean_absolute_error: 0.0131 - val_loss: 1.6332e-04 - val_mean_absolute_error: 0.0097\n","Epoch 168/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6737e-04 - mean_absolute_error: 0.0132\n","Epoch 168: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6702e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6492e-04 - val_mean_absolute_error: 0.0089\n","Epoch 169/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8262e-04 - mean_absolute_error: 0.0136\n","Epoch 169: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 38ms/step - loss: 2.8272e-04 - mean_absolute_error: 0.0136 - val_loss: 1.9194e-04 - val_mean_absolute_error: 0.0107\n","Epoch 170/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0203e-04 - mean_absolute_error: 0.0137\n","Epoch 170: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0407e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4706e-04 - val_mean_absolute_error: 0.0082\n","Epoch 171/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7907e-04 - mean_absolute_error: 0.0137\n","Epoch 171: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7881e-04 - mean_absolute_error: 0.0137 - val_loss: 1.6532e-04 - val_mean_absolute_error: 0.0087\n","Epoch 172/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6597e-04 - mean_absolute_error: 0.0134\n","Epoch 172: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6582e-04 - mean_absolute_error: 0.0134 - val_loss: 1.5581e-04 - val_mean_absolute_error: 0.0084\n","Epoch 173/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7567e-04 - mean_absolute_error: 0.0136\n","Epoch 173: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7646e-04 - mean_absolute_error: 0.0136 - val_loss: 1.9224e-04 - val_mean_absolute_error: 0.0100\n","Epoch 174/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6672e-04 - mean_absolute_error: 0.0131\n","Epoch 174: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6706e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4948e-04 - val_mean_absolute_error: 0.0091\n","Epoch 175/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8242e-04 - mean_absolute_error: 0.0135\n","Epoch 175: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8381e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6240e-04 - val_mean_absolute_error: 0.0106\n","Epoch 176/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7551e-04 - mean_absolute_error: 0.0133\n","Epoch 176: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7796e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4922e-04 - val_mean_absolute_error: 0.0082\n","Epoch 177/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9821e-04 - mean_absolute_error: 0.0139\n","Epoch 177: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9710e-04 - mean_absolute_error: 0.0138 - val_loss: 1.4832e-04 - val_mean_absolute_error: 0.0085\n","Epoch 178/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7857e-04 - mean_absolute_error: 0.0137\n","Epoch 178: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 38ms/step - loss: 2.7888e-04 - mean_absolute_error: 0.0137 - val_loss: 2.1940e-04 - val_mean_absolute_error: 0.0114\n","Epoch 179/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6652e-04 - mean_absolute_error: 0.0133\n","Epoch 179: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6815e-04 - mean_absolute_error: 0.0133 - val_loss: 1.9158e-04 - val_mean_absolute_error: 0.0103\n","Epoch 180/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0694e-04 - mean_absolute_error: 0.0140\n","Epoch 180: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0794e-04 - mean_absolute_error: 0.0140 - val_loss: 2.0181e-04 - val_mean_absolute_error: 0.0104\n","Epoch 181/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9588e-04 - mean_absolute_error: 0.0143\n","Epoch 181: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9470e-04 - mean_absolute_error: 0.0142 - val_loss: 1.9137e-04 - val_mean_absolute_error: 0.0102\n","Epoch 182/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7327e-04 - mean_absolute_error: 0.0134\n","Epoch 182: val_loss did not improve from 0.00015\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7255e-04 - mean_absolute_error: 0.0134 - val_loss: 1.5364e-04 - val_mean_absolute_error: 0.0083\n","Epoch 183/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9157e-04 - mean_absolute_error: 0.0139\n","Epoch 183: val_loss improved from 0.00015 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9070e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4330e-04 - val_mean_absolute_error: 0.0081\n","Epoch 184/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0109e-04 - mean_absolute_error: 0.0139\n","Epoch 184: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0121e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5527e-04 - val_mean_absolute_error: 0.0085\n","Epoch 185/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7704e-04 - mean_absolute_error: 0.0133\n","Epoch 185: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7572e-04 - mean_absolute_error: 0.0133 - val_loss: 1.7124e-04 - val_mean_absolute_error: 0.0092\n","Epoch 186/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9019e-04 - mean_absolute_error: 0.0139\n","Epoch 186: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8904e-04 - mean_absolute_error: 0.0139 - val_loss: 2.6367e-04 - val_mean_absolute_error: 0.0122\n","Epoch 187/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8077e-04 - mean_absolute_error: 0.0135\n","Epoch 187: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8075e-04 - mean_absolute_error: 0.0135 - val_loss: 1.4842e-04 - val_mean_absolute_error: 0.0080\n","Epoch 188/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6199e-04 - mean_absolute_error: 0.0131\n","Epoch 188: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6371e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4896e-04 - val_mean_absolute_error: 0.0084\n","Epoch 189/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7044e-04 - mean_absolute_error: 0.0131\n","Epoch 189: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6961e-04 - mean_absolute_error: 0.0131 - val_loss: 1.6693e-04 - val_mean_absolute_error: 0.0100\n","Epoch 190/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7075e-04 - mean_absolute_error: 0.0135\n","Epoch 190: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7089e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5515e-04 - val_mean_absolute_error: 0.0081\n","Epoch 191/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7456e-04 - mean_absolute_error: 0.0133\n","Epoch 191: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7423e-04 - mean_absolute_error: 0.0133 - val_loss: 1.6348e-04 - val_mean_absolute_error: 0.0089\n","Epoch 192/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8961e-04 - mean_absolute_error: 0.0136\n","Epoch 192: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8876e-04 - mean_absolute_error: 0.0136 - val_loss: 1.5132e-04 - val_mean_absolute_error: 0.0089\n","Epoch 193/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9575e-04 - mean_absolute_error: 0.0138\n","Epoch 193: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9450e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5044e-04 - val_mean_absolute_error: 0.0083\n","Epoch 194/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7921e-04 - mean_absolute_error: 0.0132\n","Epoch 194: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7921e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4170e-04 - val_mean_absolute_error: 0.0077\n","Epoch 195/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8094e-04 - mean_absolute_error: 0.0135\n","Epoch 195: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8014e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5593e-04 - val_mean_absolute_error: 0.0085\n","Epoch 196/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5884e-04 - mean_absolute_error: 0.0132\n","Epoch 196: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5884e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4526e-04 - val_mean_absolute_error: 0.0089\n","Epoch 197/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4672e-04 - mean_absolute_error: 0.0129\n","Epoch 197: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4878e-04 - mean_absolute_error: 0.0129 - val_loss: 1.8747e-04 - val_mean_absolute_error: 0.0092\n","Epoch 198/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8341e-04 - mean_absolute_error: 0.0135\n","Epoch 198: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8331e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5473e-04 - val_mean_absolute_error: 0.0086\n","Epoch 199/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6659e-04 - mean_absolute_error: 0.0133\n","Epoch 199: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6582e-04 - mean_absolute_error: 0.0132 - val_loss: 1.8385e-04 - val_mean_absolute_error: 0.0095\n","Epoch 200/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8799e-04 - mean_absolute_error: 0.0136\n","Epoch 200: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8685e-04 - mean_absolute_error: 0.0136 - val_loss: 1.6601e-04 - val_mean_absolute_error: 0.0088\n","Epoch 201/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0330e-04 - mean_absolute_error: 0.0138\n","Epoch 201: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0141e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5652e-04 - val_mean_absolute_error: 0.0086\n","Epoch 202/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7548e-04 - mean_absolute_error: 0.0135\n","Epoch 202: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7785e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6317e-04 - val_mean_absolute_error: 0.0096\n","Epoch 203/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8552e-04 - mean_absolute_error: 0.0138\n","Epoch 203: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8398e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4856e-04 - val_mean_absolute_error: 0.0081\n","Epoch 204/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9109e-04 - mean_absolute_error: 0.0136\n","Epoch 204: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8940e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4435e-04 - val_mean_absolute_error: 0.0079\n","Epoch 205/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8188e-04 - mean_absolute_error: 0.0134\n","Epoch 205: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8203e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6247e-04 - val_mean_absolute_error: 0.0086\n","Epoch 206/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6708e-04 - mean_absolute_error: 0.0132\n","Epoch 206: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6588e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4971e-04 - val_mean_absolute_error: 0.0078\n","Epoch 207/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7144e-04 - mean_absolute_error: 0.0131\n","Epoch 207: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7481e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6284e-04 - val_mean_absolute_error: 0.0086\n","Epoch 208/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7567e-04 - mean_absolute_error: 0.0134\n","Epoch 208: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7600e-04 - mean_absolute_error: 0.0134 - val_loss: 2.1350e-04 - val_mean_absolute_error: 0.0107\n","Epoch 209/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4702e-04 - mean_absolute_error: 0.0127\n","Epoch 209: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4914e-04 - mean_absolute_error: 0.0128 - val_loss: 1.7911e-04 - val_mean_absolute_error: 0.0091\n","Epoch 210/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9180e-04 - mean_absolute_error: 0.0139\n","Epoch 210: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9225e-04 - mean_absolute_error: 0.0139 - val_loss: 1.7049e-04 - val_mean_absolute_error: 0.0084\n","Epoch 211/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7738e-04 - mean_absolute_error: 0.0136\n","Epoch 211: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8121e-04 - mean_absolute_error: 0.0137 - val_loss: 2.1086e-04 - val_mean_absolute_error: 0.0100\n","Epoch 212/500\n","77/78 [============================>.] - ETA: 0s - loss: 3.0706e-04 - mean_absolute_error: 0.0143\n","Epoch 212: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 3.0707e-04 - mean_absolute_error: 0.0143 - val_loss: 1.5206e-04 - val_mean_absolute_error: 0.0080\n","Epoch 213/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7437e-04 - mean_absolute_error: 0.0135\n","Epoch 213: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7331e-04 - mean_absolute_error: 0.0135 - val_loss: 1.8458e-04 - val_mean_absolute_error: 0.0096\n","Epoch 214/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6676e-04 - mean_absolute_error: 0.0132\n","Epoch 214: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6591e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4745e-04 - val_mean_absolute_error: 0.0087\n","Epoch 215/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7213e-04 - mean_absolute_error: 0.0133\n","Epoch 215: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7106e-04 - mean_absolute_error: 0.0133 - val_loss: 1.5929e-04 - val_mean_absolute_error: 0.0092\n","Epoch 216/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8033e-04 - mean_absolute_error: 0.0135\n","Epoch 216: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7985e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6181e-04 - val_mean_absolute_error: 0.0087\n","Epoch 217/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9481e-04 - mean_absolute_error: 0.0137\n","Epoch 217: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9350e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4573e-04 - val_mean_absolute_error: 0.0087\n","Epoch 218/500\n","78/78 [==============================] - ETA: 0s - loss: 2.6818e-04 - mean_absolute_error: 0.0132\n","Epoch 218: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 42ms/step - loss: 2.6818e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4343e-04 - val_mean_absolute_error: 0.0082\n","Epoch 219/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8392e-04 - mean_absolute_error: 0.0135\n","Epoch 219: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8304e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4416e-04 - val_mean_absolute_error: 0.0080\n","Epoch 220/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7561e-04 - mean_absolute_error: 0.0133\n","Epoch 220: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7510e-04 - mean_absolute_error: 0.0133 - val_loss: 2.1616e-04 - val_mean_absolute_error: 0.0107\n","Epoch 221/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6477e-04 - mean_absolute_error: 0.0131\n","Epoch 221: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6419e-04 - mean_absolute_error: 0.0131 - val_loss: 2.0300e-04 - val_mean_absolute_error: 0.0098\n","Epoch 222/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7560e-04 - mean_absolute_error: 0.0133\n","Epoch 222: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7624e-04 - mean_absolute_error: 0.0133 - val_loss: 1.7261e-04 - val_mean_absolute_error: 0.0083\n","Epoch 223/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8316e-04 - mean_absolute_error: 0.0133\n","Epoch 223: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8555e-04 - mean_absolute_error: 0.0134 - val_loss: 1.5789e-04 - val_mean_absolute_error: 0.0093\n","Epoch 224/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7651e-04 - mean_absolute_error: 0.0132\n","Epoch 224: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7637e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4144e-04 - val_mean_absolute_error: 0.0083\n","Epoch 225/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7008e-04 - mean_absolute_error: 0.0132\n","Epoch 225: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6936e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6113e-04 - val_mean_absolute_error: 0.0083\n","Epoch 226/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8497e-04 - mean_absolute_error: 0.0137\n","Epoch 226: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8374e-04 - mean_absolute_error: 0.0137 - val_loss: 1.7501e-04 - val_mean_absolute_error: 0.0085\n","Epoch 227/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8242e-04 - mean_absolute_error: 0.0135\n","Epoch 227: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8086e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4314e-04 - val_mean_absolute_error: 0.0079\n","Epoch 228/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5655e-04 - mean_absolute_error: 0.0129\n","Epoch 228: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5655e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4375e-04 - val_mean_absolute_error: 0.0080\n","Epoch 229/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5897e-04 - mean_absolute_error: 0.0130\n","Epoch 229: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5885e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5930e-04 - val_mean_absolute_error: 0.0084\n","Epoch 230/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8696e-04 - mean_absolute_error: 0.0135\n","Epoch 230: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8535e-04 - mean_absolute_error: 0.0134 - val_loss: 1.7533e-04 - val_mean_absolute_error: 0.0087\n","Epoch 231/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8079e-04 - mean_absolute_error: 0.0134\n","Epoch 231: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7940e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4427e-04 - val_mean_absolute_error: 0.0079\n","Epoch 232/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5258e-04 - mean_absolute_error: 0.0132\n","Epoch 232: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5223e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5832e-04 - val_mean_absolute_error: 0.0092\n","Epoch 233/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7702e-04 - mean_absolute_error: 0.0133\n","Epoch 233: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7711e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4576e-04 - val_mean_absolute_error: 0.0085\n","Epoch 234/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6256e-04 - mean_absolute_error: 0.0131\n","Epoch 234: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6160e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4741e-04 - val_mean_absolute_error: 0.0093\n","Epoch 235/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5739e-04 - mean_absolute_error: 0.0131\n","Epoch 235: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5732e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5226e-04 - val_mean_absolute_error: 0.0084\n","Epoch 236/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8520e-04 - mean_absolute_error: 0.0137\n","Epoch 236: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8405e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4614e-04 - val_mean_absolute_error: 0.0085\n","Epoch 237/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7508e-04 - mean_absolute_error: 0.0133\n","Epoch 237: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7404e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4995e-04 - val_mean_absolute_error: 0.0083\n","Epoch 238/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7849e-04 - mean_absolute_error: 0.0134\n","Epoch 238: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7768e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4553e-04 - val_mean_absolute_error: 0.0085\n","Epoch 239/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7185e-04 - mean_absolute_error: 0.0135\n","Epoch 239: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7125e-04 - mean_absolute_error: 0.0135 - val_loss: 1.4900e-04 - val_mean_absolute_error: 0.0084\n","Epoch 240/500\n","78/78 [==============================] - ETA: 0s - loss: 2.6576e-04 - mean_absolute_error: 0.0133\n","Epoch 240: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6576e-04 - mean_absolute_error: 0.0133 - val_loss: 1.6393e-04 - val_mean_absolute_error: 0.0096\n","Epoch 241/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7683e-04 - mean_absolute_error: 0.0131\n","Epoch 241: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7904e-04 - mean_absolute_error: 0.0132 - val_loss: 2.2343e-04 - val_mean_absolute_error: 0.0101\n","Epoch 242/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5643e-04 - mean_absolute_error: 0.0130\n","Epoch 242: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5595e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5041e-04 - val_mean_absolute_error: 0.0081\n","Epoch 243/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6745e-04 - mean_absolute_error: 0.0130\n","Epoch 243: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6644e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3944e-04 - val_mean_absolute_error: 0.0078\n","Epoch 244/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6097e-04 - mean_absolute_error: 0.0133\n","Epoch 244: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6069e-04 - mean_absolute_error: 0.0133 - val_loss: 1.6940e-04 - val_mean_absolute_error: 0.0088\n","Epoch 245/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7448e-04 - mean_absolute_error: 0.0133\n","Epoch 245: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7442e-04 - mean_absolute_error: 0.0133 - val_loss: 1.8155e-04 - val_mean_absolute_error: 0.0087\n","Epoch 246/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8839e-04 - mean_absolute_error: 0.0137\n","Epoch 246: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8893e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4895e-04 - val_mean_absolute_error: 0.0080\n","Epoch 247/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7530e-04 - mean_absolute_error: 0.0133\n","Epoch 247: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7665e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4124e-04 - val_mean_absolute_error: 0.0079\n","Epoch 248/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7645e-04 - mean_absolute_error: 0.0133\n","Epoch 248: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8011e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6025e-04 - val_mean_absolute_error: 0.0095\n","Epoch 249/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5407e-04 - mean_absolute_error: 0.0129\n","Epoch 249: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6030e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3814e-04 - val_mean_absolute_error: 0.0077\n","Epoch 250/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6964e-04 - mean_absolute_error: 0.0131\n","Epoch 250: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6980e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4394e-04 - val_mean_absolute_error: 0.0085\n","Epoch 251/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8006e-04 - mean_absolute_error: 0.0135\n","Epoch 251: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7976e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6657e-04 - val_mean_absolute_error: 0.0083\n","Epoch 252/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6451e-04 - mean_absolute_error: 0.0131\n","Epoch 252: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6557e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4138e-04 - val_mean_absolute_error: 0.0089\n","Epoch 253/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7004e-04 - mean_absolute_error: 0.0129\n","Epoch 253: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6875e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6520e-04 - val_mean_absolute_error: 0.0089\n","Epoch 254/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9244e-04 - mean_absolute_error: 0.0137\n","Epoch 254: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9094e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4320e-04 - val_mean_absolute_error: 0.0087\n","Epoch 255/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7260e-04 - mean_absolute_error: 0.0129\n","Epoch 255: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7124e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4190e-04 - val_mean_absolute_error: 0.0078\n","Epoch 256/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7706e-04 - mean_absolute_error: 0.0133\n","Epoch 256: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7940e-04 - mean_absolute_error: 0.0133 - val_loss: 1.8568e-04 - val_mean_absolute_error: 0.0091\n","Epoch 257/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7710e-04 - mean_absolute_error: 0.0131\n","Epoch 257: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7560e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4182e-04 - val_mean_absolute_error: 0.0083\n","Epoch 258/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8233e-04 - mean_absolute_error: 0.0133\n","Epoch 258: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8107e-04 - mean_absolute_error: 0.0133 - val_loss: 1.9538e-04 - val_mean_absolute_error: 0.0100\n","Epoch 259/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5767e-04 - mean_absolute_error: 0.0131\n","Epoch 259: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5671e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4115e-04 - val_mean_absolute_error: 0.0080\n","Epoch 260/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6945e-04 - mean_absolute_error: 0.0131\n","Epoch 260: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6829e-04 - mean_absolute_error: 0.0131 - val_loss: 1.5142e-04 - val_mean_absolute_error: 0.0088\n","Epoch 261/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4345e-04 - mean_absolute_error: 0.0129\n","Epoch 261: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4400e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5108e-04 - val_mean_absolute_error: 0.0078\n","Epoch 262/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6127e-04 - mean_absolute_error: 0.0129\n","Epoch 262: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6127e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5312e-04 - val_mean_absolute_error: 0.0092\n","Epoch 263/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6098e-04 - mean_absolute_error: 0.0131\n","Epoch 263: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6488e-04 - mean_absolute_error: 0.0131 - val_loss: 1.6988e-04 - val_mean_absolute_error: 0.0096\n","Epoch 264/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7735e-04 - mean_absolute_error: 0.0133\n","Epoch 264: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7735e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4732e-04 - val_mean_absolute_error: 0.0090\n","Epoch 265/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6065e-04 - mean_absolute_error: 0.0129\n","Epoch 265: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6257e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6783e-04 - val_mean_absolute_error: 0.0084\n","Epoch 266/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5766e-04 - mean_absolute_error: 0.0128\n","Epoch 266: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5612e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4671e-04 - val_mean_absolute_error: 0.0079\n","Epoch 267/500\n","78/78 [==============================] - ETA: 0s - loss: 2.8885e-04 - mean_absolute_error: 0.0134\n","Epoch 267: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8885e-04 - mean_absolute_error: 0.0134 - val_loss: 2.3160e-04 - val_mean_absolute_error: 0.0109\n","Epoch 268/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7454e-04 - mean_absolute_error: 0.0131\n","Epoch 268: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7664e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3762e-04 - val_mean_absolute_error: 0.0077\n","Epoch 269/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8075e-04 - mean_absolute_error: 0.0134\n","Epoch 269: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7925e-04 - mean_absolute_error: 0.0133 - val_loss: 1.6067e-04 - val_mean_absolute_error: 0.0083\n","Epoch 270/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8750e-04 - mean_absolute_error: 0.0134\n","Epoch 270: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8716e-04 - mean_absolute_error: 0.0134 - val_loss: 1.5336e-04 - val_mean_absolute_error: 0.0087\n","Epoch 271/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8000e-04 - mean_absolute_error: 0.0133\n","Epoch 271: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8098e-04 - mean_absolute_error: 0.0133 - val_loss: 1.5606e-04 - val_mean_absolute_error: 0.0080\n","Epoch 272/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5764e-04 - mean_absolute_error: 0.0128\n","Epoch 272: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5779e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6903e-04 - val_mean_absolute_error: 0.0098\n","Epoch 273/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7593e-04 - mean_absolute_error: 0.0135\n","Epoch 273: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7526e-04 - mean_absolute_error: 0.0135 - val_loss: 1.3754e-04 - val_mean_absolute_error: 0.0079\n","Epoch 274/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7325e-04 - mean_absolute_error: 0.0132\n","Epoch 274: val_loss improved from 0.00014 to 0.00014, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7174e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3613e-04 - val_mean_absolute_error: 0.0077\n","Epoch 275/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6493e-04 - mean_absolute_error: 0.0131\n","Epoch 275: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6626e-04 - mean_absolute_error: 0.0132 - val_loss: 1.7136e-04 - val_mean_absolute_error: 0.0087\n","Epoch 276/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8234e-04 - mean_absolute_error: 0.0133\n","Epoch 276: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.8143e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4340e-04 - val_mean_absolute_error: 0.0079\n","Epoch 277/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9589e-04 - mean_absolute_error: 0.0137\n","Epoch 277: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9561e-04 - mean_absolute_error: 0.0137 - val_loss: 1.6720e-04 - val_mean_absolute_error: 0.0085\n","Epoch 278/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5802e-04 - mean_absolute_error: 0.0130\n","Epoch 278: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5777e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4367e-04 - val_mean_absolute_error: 0.0087\n","Epoch 279/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8478e-04 - mean_absolute_error: 0.0135\n","Epoch 279: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8392e-04 - mean_absolute_error: 0.0134 - val_loss: 1.3863e-04 - val_mean_absolute_error: 0.0076\n","Epoch 280/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5289e-04 - mean_absolute_error: 0.0130\n","Epoch 280: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5482e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4254e-04 - val_mean_absolute_error: 0.0090\n","Epoch 281/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6606e-04 - mean_absolute_error: 0.0133\n","Epoch 281: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6723e-04 - mean_absolute_error: 0.0133 - val_loss: 1.5741e-04 - val_mean_absolute_error: 0.0092\n","Epoch 282/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7583e-04 - mean_absolute_error: 0.0132\n","Epoch 282: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7658e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4629e-04 - val_mean_absolute_error: 0.0088\n","Epoch 283/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5277e-04 - mean_absolute_error: 0.0126\n","Epoch 283: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5528e-04 - mean_absolute_error: 0.0126 - val_loss: 1.6351e-04 - val_mean_absolute_error: 0.0089\n","Epoch 284/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6375e-04 - mean_absolute_error: 0.0130\n","Epoch 284: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6430e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4026e-04 - val_mean_absolute_error: 0.0079\n","Epoch 285/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5838e-04 - mean_absolute_error: 0.0129\n","Epoch 285: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5831e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5343e-04 - val_mean_absolute_error: 0.0080\n","Epoch 286/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4830e-04 - mean_absolute_error: 0.0127\n","Epoch 286: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4917e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5182e-04 - val_mean_absolute_error: 0.0084\n","Epoch 287/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8254e-04 - mean_absolute_error: 0.0133\n","Epoch 287: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8141e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4386e-04 - val_mean_absolute_error: 0.0081\n","Epoch 288/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6236e-04 - mean_absolute_error: 0.0131\n","Epoch 288: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6300e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4591e-04 - val_mean_absolute_error: 0.0083\n","Epoch 289/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7167e-04 - mean_absolute_error: 0.0134\n","Epoch 289: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7063e-04 - mean_absolute_error: 0.0133 - val_loss: 1.8475e-04 - val_mean_absolute_error: 0.0094\n","Epoch 290/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6585e-04 - mean_absolute_error: 0.0132\n","Epoch 290: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6528e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6335e-04 - val_mean_absolute_error: 0.0096\n","Epoch 291/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7481e-04 - mean_absolute_error: 0.0133\n","Epoch 291: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7415e-04 - mean_absolute_error: 0.0133 - val_loss: 1.3960e-04 - val_mean_absolute_error: 0.0081\n","Epoch 292/500\n","78/78 [==============================] - ETA: 0s - loss: 2.4839e-04 - mean_absolute_error: 0.0127\n","Epoch 292: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.4839e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4426e-04 - val_mean_absolute_error: 0.0081\n","Epoch 293/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6376e-04 - mean_absolute_error: 0.0130\n","Epoch 293: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6655e-04 - mean_absolute_error: 0.0130 - val_loss: 1.9114e-04 - val_mean_absolute_error: 0.0099\n","Epoch 294/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9586e-04 - mean_absolute_error: 0.0136\n","Epoch 294: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 3.0103e-04 - mean_absolute_error: 0.0137 - val_loss: 1.3765e-04 - val_mean_absolute_error: 0.0084\n","Epoch 295/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7360e-04 - mean_absolute_error: 0.0132\n","Epoch 295: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7220e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4640e-04 - val_mean_absolute_error: 0.0096\n","Epoch 296/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9345e-04 - mean_absolute_error: 0.0138\n","Epoch 296: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9341e-04 - mean_absolute_error: 0.0138 - val_loss: 1.5466e-04 - val_mean_absolute_error: 0.0094\n","Epoch 297/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7762e-04 - mean_absolute_error: 0.0134\n","Epoch 297: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7668e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6501e-04 - val_mean_absolute_error: 0.0088\n","Epoch 298/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5813e-04 - mean_absolute_error: 0.0129\n","Epoch 298: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5717e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5569e-04 - val_mean_absolute_error: 0.0089\n","Epoch 299/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7715e-04 - mean_absolute_error: 0.0136\n","Epoch 299: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7930e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4230e-04 - val_mean_absolute_error: 0.0085\n","Epoch 300/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5895e-04 - mean_absolute_error: 0.0131\n","Epoch 300: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5766e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6351e-04 - val_mean_absolute_error: 0.0085\n","Epoch 301/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7177e-04 - mean_absolute_error: 0.0131\n","Epoch 301: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7112e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3648e-04 - val_mean_absolute_error: 0.0079\n","Epoch 302/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5398e-04 - mean_absolute_error: 0.0128\n","Epoch 302: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.5288e-04 - mean_absolute_error: 0.0128 - val_loss: 1.5598e-04 - val_mean_absolute_error: 0.0090\n","Epoch 303/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8155e-04 - mean_absolute_error: 0.0134\n","Epoch 303: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8136e-04 - mean_absolute_error: 0.0134 - val_loss: 1.7387e-04 - val_mean_absolute_error: 0.0099\n","Epoch 304/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6436e-04 - mean_absolute_error: 0.0130\n","Epoch 304: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6487e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6849e-04 - val_mean_absolute_error: 0.0089\n","Epoch 305/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5212e-04 - mean_absolute_error: 0.0127\n","Epoch 305: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.5509e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3805e-04 - val_mean_absolute_error: 0.0080\n","Epoch 306/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6853e-04 - mean_absolute_error: 0.0131\n","Epoch 306: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6893e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3872e-04 - val_mean_absolute_error: 0.0080\n","Epoch 307/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6969e-04 - mean_absolute_error: 0.0131\n","Epoch 307: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6845e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4878e-04 - val_mean_absolute_error: 0.0086\n","Epoch 308/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7035e-04 - mean_absolute_error: 0.0132\n","Epoch 308: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6950e-04 - mean_absolute_error: 0.0132 - val_loss: 1.8211e-04 - val_mean_absolute_error: 0.0098\n","Epoch 309/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7713e-04 - mean_absolute_error: 0.0133\n","Epoch 309: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7607e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4648e-04 - val_mean_absolute_error: 0.0085\n","Epoch 310/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5377e-04 - mean_absolute_error: 0.0129\n","Epoch 310: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5257e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4098e-04 - val_mean_absolute_error: 0.0077\n","Epoch 311/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6268e-04 - mean_absolute_error: 0.0131\n","Epoch 311: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6163e-04 - mean_absolute_error: 0.0131 - val_loss: 1.5876e-04 - val_mean_absolute_error: 0.0080\n","Epoch 312/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7472e-04 - mean_absolute_error: 0.0133\n","Epoch 312: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7698e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4679e-04 - val_mean_absolute_error: 0.0078\n","Epoch 313/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5627e-04 - mean_absolute_error: 0.0129\n","Epoch 313: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5627e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4411e-04 - val_mean_absolute_error: 0.0076\n","Epoch 314/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5495e-04 - mean_absolute_error: 0.0129\n","Epoch 314: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5414e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4789e-04 - val_mean_absolute_error: 0.0095\n","Epoch 315/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6824e-04 - mean_absolute_error: 0.0131\n","Epoch 315: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6799e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6065e-04 - val_mean_absolute_error: 0.0086\n","Epoch 316/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8139e-04 - mean_absolute_error: 0.0132\n","Epoch 316: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8000e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5860e-04 - val_mean_absolute_error: 0.0089\n","Epoch 317/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7419e-04 - mean_absolute_error: 0.0132\n","Epoch 317: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7348e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4599e-04 - val_mean_absolute_error: 0.0079\n","Epoch 318/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9561e-04 - mean_absolute_error: 0.0134\n","Epoch 318: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9693e-04 - mean_absolute_error: 0.0134 - val_loss: 3.1234e-04 - val_mean_absolute_error: 0.0119\n","Epoch 319/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9811e-04 - mean_absolute_error: 0.0138\n","Epoch 319: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9734e-04 - mean_absolute_error: 0.0138 - val_loss: 1.7065e-04 - val_mean_absolute_error: 0.0085\n","Epoch 320/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5956e-04 - mean_absolute_error: 0.0131\n","Epoch 320: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5822e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4551e-04 - val_mean_absolute_error: 0.0082\n","Epoch 321/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4804e-04 - mean_absolute_error: 0.0126\n","Epoch 321: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4948e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4474e-04 - val_mean_absolute_error: 0.0087\n","Epoch 322/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5599e-04 - mean_absolute_error: 0.0129\n","Epoch 322: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5901e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4963e-04 - val_mean_absolute_error: 0.0077\n","Epoch 323/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7472e-04 - mean_absolute_error: 0.0133\n","Epoch 323: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7531e-04 - mean_absolute_error: 0.0133 - val_loss: 1.6655e-04 - val_mean_absolute_error: 0.0086\n","Epoch 324/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5623e-04 - mean_absolute_error: 0.0128\n","Epoch 324: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5652e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4857e-04 - val_mean_absolute_error: 0.0079\n","Epoch 325/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9956e-04 - mean_absolute_error: 0.0137\n","Epoch 325: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.9879e-04 - mean_absolute_error: 0.0137 - val_loss: 1.8987e-04 - val_mean_absolute_error: 0.0101\n","Epoch 326/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9215e-04 - mean_absolute_error: 0.0135\n","Epoch 326: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.9058e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5134e-04 - val_mean_absolute_error: 0.0090\n","Epoch 327/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6333e-04 - mean_absolute_error: 0.0132\n","Epoch 327: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6259e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4388e-04 - val_mean_absolute_error: 0.0080\n","Epoch 328/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7253e-04 - mean_absolute_error: 0.0133\n","Epoch 328: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7467e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4285e-04 - val_mean_absolute_error: 0.0079\n","Epoch 329/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5981e-04 - mean_absolute_error: 0.0130\n","Epoch 329: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6002e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4593e-04 - val_mean_absolute_error: 0.0080\n","Epoch 330/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6971e-04 - mean_absolute_error: 0.0130\n","Epoch 330: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6875e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6014e-04 - val_mean_absolute_error: 0.0086\n","Epoch 331/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7817e-04 - mean_absolute_error: 0.0132\n","Epoch 331: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7817e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5962e-04 - val_mean_absolute_error: 0.0083\n","Epoch 332/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9458e-04 - mean_absolute_error: 0.0135\n","Epoch 332: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.9452e-04 - mean_absolute_error: 0.0135 - val_loss: 1.4011e-04 - val_mean_absolute_error: 0.0088\n","Epoch 333/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6585e-04 - mean_absolute_error: 0.0130\n","Epoch 333: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6440e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5235e-04 - val_mean_absolute_error: 0.0091\n","Epoch 334/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5396e-04 - mean_absolute_error: 0.0130\n","Epoch 334: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5520e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4300e-04 - val_mean_absolute_error: 0.0079\n","Epoch 335/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7340e-04 - mean_absolute_error: 0.0133\n","Epoch 335: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7363e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4423e-04 - val_mean_absolute_error: 0.0082\n","Epoch 336/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5879e-04 - mean_absolute_error: 0.0130\n","Epoch 336: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6192e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4598e-04 - val_mean_absolute_error: 0.0088\n","Epoch 337/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6964e-04 - mean_absolute_error: 0.0134\n","Epoch 337: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6877e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4043e-04 - val_mean_absolute_error: 0.0081\n","Epoch 338/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6255e-04 - mean_absolute_error: 0.0129\n","Epoch 338: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6359e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6179e-04 - val_mean_absolute_error: 0.0087\n","Epoch 339/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6113e-04 - mean_absolute_error: 0.0130\n","Epoch 339: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6033e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6328e-04 - val_mean_absolute_error: 0.0090\n","Epoch 340/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5493e-04 - mean_absolute_error: 0.0128\n","Epoch 340: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5471e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3890e-04 - val_mean_absolute_error: 0.0084\n","Epoch 341/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6213e-04 - mean_absolute_error: 0.0130\n","Epoch 341: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6127e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3754e-04 - val_mean_absolute_error: 0.0087\n","Epoch 342/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5019e-04 - mean_absolute_error: 0.0129\n","Epoch 342: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4997e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4077e-04 - val_mean_absolute_error: 0.0080\n","Epoch 343/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8525e-04 - mean_absolute_error: 0.0134\n","Epoch 343: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8552e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6699e-04 - val_mean_absolute_error: 0.0100\n","Epoch 344/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5442e-04 - mean_absolute_error: 0.0129\n","Epoch 344: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5357e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4157e-04 - val_mean_absolute_error: 0.0078\n","Epoch 345/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6285e-04 - mean_absolute_error: 0.0130\n","Epoch 345: val_loss did not improve from 0.00014\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6253e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3903e-04 - val_mean_absolute_error: 0.0080\n","Epoch 346/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7056e-04 - mean_absolute_error: 0.0130\n","Epoch 346: val_loss improved from 0.00014 to 0.00013, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6970e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3499e-04 - val_mean_absolute_error: 0.0078\n","Epoch 347/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5634e-04 - mean_absolute_error: 0.0128\n","Epoch 347: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5667e-04 - mean_absolute_error: 0.0128 - val_loss: 1.5481e-04 - val_mean_absolute_error: 0.0084\n","Epoch 348/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8428e-04 - mean_absolute_error: 0.0134\n","Epoch 348: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8287e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4333e-04 - val_mean_absolute_error: 0.0082\n","Epoch 349/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5316e-04 - mean_absolute_error: 0.0130\n","Epoch 349: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5265e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5744e-04 - val_mean_absolute_error: 0.0080\n","Epoch 350/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4488e-04 - mean_absolute_error: 0.0126\n","Epoch 350: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4433e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4110e-04 - val_mean_absolute_error: 0.0082\n","Epoch 351/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6334e-04 - mean_absolute_error: 0.0130\n","Epoch 351: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6737e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3793e-04 - val_mean_absolute_error: 0.0079\n","Epoch 352/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6625e-04 - mean_absolute_error: 0.0132\n","Epoch 352: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6510e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4271e-04 - val_mean_absolute_error: 0.0083\n","Epoch 353/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7065e-04 - mean_absolute_error: 0.0133\n","Epoch 353: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7027e-04 - mean_absolute_error: 0.0133 - val_loss: 1.3771e-04 - val_mean_absolute_error: 0.0079\n","Epoch 354/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5164e-04 - mean_absolute_error: 0.0127\n","Epoch 354: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5332e-04 - mean_absolute_error: 0.0127 - val_loss: 1.7801e-04 - val_mean_absolute_error: 0.0086\n","Epoch 355/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5923e-04 - mean_absolute_error: 0.0128\n","Epoch 355: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5836e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4389e-04 - val_mean_absolute_error: 0.0086\n","Epoch 356/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6055e-04 - mean_absolute_error: 0.0128\n","Epoch 356: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5994e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4069e-04 - val_mean_absolute_error: 0.0085\n","Epoch 357/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5249e-04 - mean_absolute_error: 0.0128\n","Epoch 357: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5581e-04 - mean_absolute_error: 0.0129 - val_loss: 1.7309e-04 - val_mean_absolute_error: 0.0091\n","Epoch 358/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6330e-04 - mean_absolute_error: 0.0128\n","Epoch 358: val_loss improved from 0.00013 to 0.00013, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6229e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3400e-04 - val_mean_absolute_error: 0.0075\n","Epoch 359/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4070e-04 - mean_absolute_error: 0.0128\n","Epoch 359: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4009e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4262e-04 - val_mean_absolute_error: 0.0082\n","Epoch 360/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5285e-04 - mean_absolute_error: 0.0127\n","Epoch 360: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5206e-04 - mean_absolute_error: 0.0127 - val_loss: 2.0202e-04 - val_mean_absolute_error: 0.0105\n","Epoch 361/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7539e-04 - mean_absolute_error: 0.0132\n","Epoch 361: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 38ms/step - loss: 2.7515e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3788e-04 - val_mean_absolute_error: 0.0080\n","Epoch 362/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6054e-04 - mean_absolute_error: 0.0130\n","Epoch 362: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6023e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4953e-04 - val_mean_absolute_error: 0.0079\n","Epoch 363/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7229e-04 - mean_absolute_error: 0.0131\n","Epoch 363: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7283e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4806e-04 - val_mean_absolute_error: 0.0081\n","Epoch 364/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5713e-04 - mean_absolute_error: 0.0125\n","Epoch 364: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5713e-04 - mean_absolute_error: 0.0125 - val_loss: 1.6385e-04 - val_mean_absolute_error: 0.0091\n","Epoch 365/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6475e-04 - mean_absolute_error: 0.0130\n","Epoch 365: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6352e-04 - mean_absolute_error: 0.0129 - val_loss: 1.7019e-04 - val_mean_absolute_error: 0.0090\n","Epoch 366/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6786e-04 - mean_absolute_error: 0.0132\n","Epoch 366: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6675e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5530e-04 - val_mean_absolute_error: 0.0100\n","Epoch 367/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7023e-04 - mean_absolute_error: 0.0130\n","Epoch 367: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7298e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4558e-04 - val_mean_absolute_error: 0.0081\n","Epoch 368/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6210e-04 - mean_absolute_error: 0.0131\n","Epoch 368: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6120e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6288e-04 - val_mean_absolute_error: 0.0089\n","Epoch 369/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4692e-04 - mean_absolute_error: 0.0127\n","Epoch 369: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4649e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5022e-04 - val_mean_absolute_error: 0.0088\n","Epoch 370/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6336e-04 - mean_absolute_error: 0.0128\n","Epoch 370: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6255e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4735e-04 - val_mean_absolute_error: 0.0084\n","Epoch 371/500\n","78/78 [==============================] - ETA: 0s - loss: 2.6288e-04 - mean_absolute_error: 0.0128\n","Epoch 371: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6288e-04 - mean_absolute_error: 0.0128 - val_loss: 1.6279e-04 - val_mean_absolute_error: 0.0080\n","Epoch 372/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7478e-04 - mean_absolute_error: 0.0133\n","Epoch 372: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7457e-04 - mean_absolute_error: 0.0133 - val_loss: 1.3898e-04 - val_mean_absolute_error: 0.0077\n","Epoch 373/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5275e-04 - mean_absolute_error: 0.0126\n","Epoch 373: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 38ms/step - loss: 2.5256e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4896e-04 - val_mean_absolute_error: 0.0077\n","Epoch 374/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5772e-04 - mean_absolute_error: 0.0130\n","Epoch 374: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5872e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5299e-04 - val_mean_absolute_error: 0.0081\n","Epoch 375/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6240e-04 - mean_absolute_error: 0.0129\n","Epoch 375: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6334e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3687e-04 - val_mean_absolute_error: 0.0078\n","Epoch 376/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5143e-04 - mean_absolute_error: 0.0129\n","Epoch 376: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5205e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3780e-04 - val_mean_absolute_error: 0.0079\n","Epoch 377/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6492e-04 - mean_absolute_error: 0.0128\n","Epoch 377: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6540e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3655e-04 - val_mean_absolute_error: 0.0083\n","Epoch 378/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4964e-04 - mean_absolute_error: 0.0127\n","Epoch 378: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4873e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3694e-04 - val_mean_absolute_error: 0.0080\n","Epoch 379/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5964e-04 - mean_absolute_error: 0.0128\n","Epoch 379: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5943e-04 - mean_absolute_error: 0.0128 - val_loss: 1.7539e-04 - val_mean_absolute_error: 0.0089\n","Epoch 380/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7125e-04 - mean_absolute_error: 0.0128\n","Epoch 380: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7075e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4997e-04 - val_mean_absolute_error: 0.0095\n","Epoch 381/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7801e-04 - mean_absolute_error: 0.0132\n","Epoch 381: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7691e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4057e-04 - val_mean_absolute_error: 0.0089\n","Epoch 382/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5851e-04 - mean_absolute_error: 0.0129\n","Epoch 382: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5731e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3626e-04 - val_mean_absolute_error: 0.0079\n","Epoch 383/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6080e-04 - mean_absolute_error: 0.0128\n","Epoch 383: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6068e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3493e-04 - val_mean_absolute_error: 0.0080\n","Epoch 384/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5252e-04 - mean_absolute_error: 0.0128\n","Epoch 384: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5268e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4552e-04 - val_mean_absolute_error: 0.0083\n","Epoch 385/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6475e-04 - mean_absolute_error: 0.0128\n","Epoch 385: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6398e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4630e-04 - val_mean_absolute_error: 0.0085\n","Epoch 386/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6230e-04 - mean_absolute_error: 0.0132\n","Epoch 386: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6096e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4553e-04 - val_mean_absolute_error: 0.0082\n","Epoch 387/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7144e-04 - mean_absolute_error: 0.0130\n","Epoch 387: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7000e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5786e-04 - val_mean_absolute_error: 0.0090\n","Epoch 388/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6628e-04 - mean_absolute_error: 0.0129\n","Epoch 388: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6769e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4034e-04 - val_mean_absolute_error: 0.0087\n","Epoch 389/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7413e-04 - mean_absolute_error: 0.0132\n","Epoch 389: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7442e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5316e-04 - val_mean_absolute_error: 0.0084\n","Epoch 390/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5364e-04 - mean_absolute_error: 0.0128\n","Epoch 390: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5359e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4147e-04 - val_mean_absolute_error: 0.0078\n","Epoch 391/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6237e-04 - mean_absolute_error: 0.0128\n","Epoch 391: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6091e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5660e-04 - val_mean_absolute_error: 0.0086\n","Epoch 392/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5515e-04 - mean_absolute_error: 0.0128\n","Epoch 392: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5437e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3829e-04 - val_mean_absolute_error: 0.0084\n","Epoch 393/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5140e-04 - mean_absolute_error: 0.0130\n","Epoch 393: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5140e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5076e-04 - val_mean_absolute_error: 0.0084\n","Epoch 394/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4860e-04 - mean_absolute_error: 0.0127\n","Epoch 394: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.4914e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4693e-04 - val_mean_absolute_error: 0.0081\n","Epoch 395/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5901e-04 - mean_absolute_error: 0.0129\n","Epoch 395: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5822e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3741e-04 - val_mean_absolute_error: 0.0078\n","Epoch 396/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5579e-04 - mean_absolute_error: 0.0125\n","Epoch 396: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.5514e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4324e-04 - val_mean_absolute_error: 0.0078\n","Epoch 397/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.9039e-04 - mean_absolute_error: 0.0133\n","Epoch 397: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.8870e-04 - mean_absolute_error: 0.0133 - val_loss: 1.3609e-04 - val_mean_absolute_error: 0.0078\n","Epoch 398/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7090e-04 - mean_absolute_error: 0.0129\n","Epoch 398: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7090e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3479e-04 - val_mean_absolute_error: 0.0081\n","Epoch 399/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6569e-04 - mean_absolute_error: 0.0130\n","Epoch 399: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6639e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4641e-04 - val_mean_absolute_error: 0.0085\n","Epoch 400/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6725e-04 - mean_absolute_error: 0.0131\n","Epoch 400: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6670e-04 - mean_absolute_error: 0.0131 - val_loss: 2.1230e-04 - val_mean_absolute_error: 0.0100\n","Epoch 401/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5173e-04 - mean_absolute_error: 0.0128\n","Epoch 401: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5311e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4234e-04 - val_mean_absolute_error: 0.0076\n","Epoch 402/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6480e-04 - mean_absolute_error: 0.0129\n","Epoch 402: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6713e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3899e-04 - val_mean_absolute_error: 0.0076\n","Epoch 403/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7954e-04 - mean_absolute_error: 0.0133\n","Epoch 403: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 38ms/step - loss: 2.8136e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4428e-04 - val_mean_absolute_error: 0.0079\n","Epoch 404/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4793e-04 - mean_absolute_error: 0.0127\n","Epoch 404: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4977e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4657e-04 - val_mean_absolute_error: 0.0083\n","Epoch 405/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5692e-04 - mean_absolute_error: 0.0128\n","Epoch 405: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5704e-04 - mean_absolute_error: 0.0128 - val_loss: 1.6684e-04 - val_mean_absolute_error: 0.0095\n","Epoch 406/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4845e-04 - mean_absolute_error: 0.0127\n","Epoch 406: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4836e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3949e-04 - val_mean_absolute_error: 0.0076\n","Epoch 407/500\n","78/78 [==============================] - ETA: 0s - loss: 2.4521e-04 - mean_absolute_error: 0.0126\n","Epoch 407: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4521e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3615e-04 - val_mean_absolute_error: 0.0078\n","Epoch 408/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5580e-04 - mean_absolute_error: 0.0126\n","Epoch 408: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5660e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3908e-04 - val_mean_absolute_error: 0.0088\n","Epoch 409/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5225e-04 - mean_absolute_error: 0.0127\n","Epoch 409: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5287e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4025e-04 - val_mean_absolute_error: 0.0083\n","Epoch 410/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6181e-04 - mean_absolute_error: 0.0129\n","Epoch 410: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6057e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6141e-04 - val_mean_absolute_error: 0.0099\n","Epoch 411/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5014e-04 - mean_absolute_error: 0.0128\n","Epoch 411: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4896e-04 - mean_absolute_error: 0.0127 - val_loss: 1.6148e-04 - val_mean_absolute_error: 0.0084\n","Epoch 412/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4684e-04 - mean_absolute_error: 0.0125\n","Epoch 412: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4553e-04 - mean_absolute_error: 0.0124 - val_loss: 1.5738e-04 - val_mean_absolute_error: 0.0085\n","Epoch 413/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7483e-04 - mean_absolute_error: 0.0132\n","Epoch 413: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7483e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3994e-04 - val_mean_absolute_error: 0.0079\n","Epoch 414/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4023e-04 - mean_absolute_error: 0.0124\n","Epoch 414: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4275e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4391e-04 - val_mean_absolute_error: 0.0093\n","Epoch 415/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8856e-04 - mean_absolute_error: 0.0135\n","Epoch 415: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.8731e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4983e-04 - val_mean_absolute_error: 0.0087\n","Epoch 416/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5191e-04 - mean_absolute_error: 0.0127\n","Epoch 416: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5437e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4227e-04 - val_mean_absolute_error: 0.0078\n","Epoch 417/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7660e-04 - mean_absolute_error: 0.0132\n","Epoch 417: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7623e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4011e-04 - val_mean_absolute_error: 0.0076\n","Epoch 418/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5984e-04 - mean_absolute_error: 0.0128\n","Epoch 418: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6102e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4310e-04 - val_mean_absolute_error: 0.0077\n","Epoch 419/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6524e-04 - mean_absolute_error: 0.0128\n","Epoch 419: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6805e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4369e-04 - val_mean_absolute_error: 0.0081\n","Epoch 420/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5832e-04 - mean_absolute_error: 0.0127\n","Epoch 420: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5690e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4689e-04 - val_mean_absolute_error: 0.0082\n","Epoch 421/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5946e-04 - mean_absolute_error: 0.0129\n","Epoch 421: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5923e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6080e-04 - val_mean_absolute_error: 0.0102\n","Epoch 422/500\n","78/78 [==============================] - ETA: 0s - loss: 2.6357e-04 - mean_absolute_error: 0.0128\n","Epoch 422: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6357e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4409e-04 - val_mean_absolute_error: 0.0080\n","Epoch 423/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4815e-04 - mean_absolute_error: 0.0126\n","Epoch 423: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 38ms/step - loss: 2.4692e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4864e-04 - val_mean_absolute_error: 0.0079\n","Epoch 424/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6839e-04 - mean_absolute_error: 0.0128\n","Epoch 424: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6802e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4511e-04 - val_mean_absolute_error: 0.0082\n","Epoch 425/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5429e-04 - mean_absolute_error: 0.0128\n","Epoch 425: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5392e-04 - mean_absolute_error: 0.0128 - val_loss: 2.0617e-04 - val_mean_absolute_error: 0.0102\n","Epoch 426/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7843e-04 - mean_absolute_error: 0.0131\n","Epoch 426: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7799e-04 - mean_absolute_error: 0.0131 - val_loss: 1.9634e-04 - val_mean_absolute_error: 0.0098\n","Epoch 427/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4884e-04 - mean_absolute_error: 0.0128\n","Epoch 427: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4835e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4589e-04 - val_mean_absolute_error: 0.0079\n","Epoch 428/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3878e-04 - mean_absolute_error: 0.0125\n","Epoch 428: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.3982e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3411e-04 - val_mean_absolute_error: 0.0076\n","Epoch 429/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.8011e-04 - mean_absolute_error: 0.0131\n","Epoch 429: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7971e-04 - mean_absolute_error: 0.0131 - val_loss: 1.5062e-04 - val_mean_absolute_error: 0.0080\n","Epoch 430/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4820e-04 - mean_absolute_error: 0.0127\n","Epoch 430: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4787e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5080e-04 - val_mean_absolute_error: 0.0081\n","Epoch 431/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7302e-04 - mean_absolute_error: 0.0131\n","Epoch 431: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7300e-04 - mean_absolute_error: 0.0131 - val_loss: 1.5328e-04 - val_mean_absolute_error: 0.0082\n","Epoch 432/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5372e-04 - mean_absolute_error: 0.0128\n","Epoch 432: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5240e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3803e-04 - val_mean_absolute_error: 0.0077\n","Epoch 433/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3942e-04 - mean_absolute_error: 0.0127\n","Epoch 433: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4100e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4488e-04 - val_mean_absolute_error: 0.0078\n","Epoch 434/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4373e-04 - mean_absolute_error: 0.0127\n","Epoch 434: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4470e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3820e-04 - val_mean_absolute_error: 0.0079\n","Epoch 435/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5144e-04 - mean_absolute_error: 0.0128\n","Epoch 435: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5049e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3915e-04 - val_mean_absolute_error: 0.0077\n","Epoch 436/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3783e-04 - mean_absolute_error: 0.0125\n","Epoch 436: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.3832e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3821e-04 - val_mean_absolute_error: 0.0079\n","Epoch 437/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3846e-04 - mean_absolute_error: 0.0122\n","Epoch 437: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.3981e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3758e-04 - val_mean_absolute_error: 0.0077\n","Epoch 438/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4901e-04 - mean_absolute_error: 0.0127\n","Epoch 438: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4774e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3826e-04 - val_mean_absolute_error: 0.0081\n","Epoch 439/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4257e-04 - mean_absolute_error: 0.0125\n","Epoch 439: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4219e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3701e-04 - val_mean_absolute_error: 0.0077\n","Epoch 440/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4645e-04 - mean_absolute_error: 0.0125\n","Epoch 440: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.4723e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4933e-04 - val_mean_absolute_error: 0.0086\n","Epoch 441/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5569e-04 - mean_absolute_error: 0.0127\n","Epoch 441: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5531e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3989e-04 - val_mean_absolute_error: 0.0078\n","Epoch 442/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5036e-04 - mean_absolute_error: 0.0126\n","Epoch 442: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4911e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3626e-04 - val_mean_absolute_error: 0.0075\n","Epoch 443/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.2644e-04 - mean_absolute_error: 0.0122\n","Epoch 443: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.2730e-04 - mean_absolute_error: 0.0121 - val_loss: 1.4411e-04 - val_mean_absolute_error: 0.0076\n","Epoch 444/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5782e-04 - mean_absolute_error: 0.0128\n","Epoch 444: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5684e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3607e-04 - val_mean_absolute_error: 0.0075\n","Epoch 445/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5509e-04 - mean_absolute_error: 0.0125\n","Epoch 445: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5412e-04 - mean_absolute_error: 0.0125 - val_loss: 1.5044e-04 - val_mean_absolute_error: 0.0084\n","Epoch 446/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4485e-04 - mean_absolute_error: 0.0122\n","Epoch 446: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4667e-04 - mean_absolute_error: 0.0123 - val_loss: 1.6330e-04 - val_mean_absolute_error: 0.0081\n","Epoch 447/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6809e-04 - mean_absolute_error: 0.0131\n","Epoch 447: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6676e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4651e-04 - val_mean_absolute_error: 0.0080\n","Epoch 448/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7692e-04 - mean_absolute_error: 0.0131\n","Epoch 448: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7601e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4752e-04 - val_mean_absolute_error: 0.0081\n","Epoch 449/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6757e-04 - mean_absolute_error: 0.0126\n","Epoch 449: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6673e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5074e-04 - val_mean_absolute_error: 0.0080\n","Epoch 450/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6679e-04 - mean_absolute_error: 0.0129\n","Epoch 450: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6593e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3980e-04 - val_mean_absolute_error: 0.0076\n","Epoch 451/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4622e-04 - mean_absolute_error: 0.0126\n","Epoch 451: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4587e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5476e-04 - val_mean_absolute_error: 0.0083\n","Epoch 452/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4695e-04 - mean_absolute_error: 0.0124\n","Epoch 452: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4922e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3863e-04 - val_mean_absolute_error: 0.0080\n","Epoch 453/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4109e-04 - mean_absolute_error: 0.0123\n","Epoch 453: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4189e-04 - mean_absolute_error: 0.0123 - val_loss: 1.6758e-04 - val_mean_absolute_error: 0.0103\n","Epoch 454/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6067e-04 - mean_absolute_error: 0.0130\n","Epoch 454: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6109e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3815e-04 - val_mean_absolute_error: 0.0080\n","Epoch 455/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7224e-04 - mean_absolute_error: 0.0129\n","Epoch 455: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7228e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3622e-04 - val_mean_absolute_error: 0.0078\n","Epoch 456/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4986e-04 - mean_absolute_error: 0.0127\n","Epoch 456: val_loss improved from 0.00013 to 0.00013, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4950e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3223e-04 - val_mean_absolute_error: 0.0078\n","Epoch 457/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5602e-04 - mean_absolute_error: 0.0125\n","Epoch 457: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5587e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4941e-04 - val_mean_absolute_error: 0.0084\n","Epoch 458/500\n","78/78 [==============================] - ETA: 0s - loss: 2.5453e-04 - mean_absolute_error: 0.0129\n","Epoch 458: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.5453e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4769e-04 - val_mean_absolute_error: 0.0084\n","Epoch 459/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6734e-04 - mean_absolute_error: 0.0129\n","Epoch 459: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.6616e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4935e-04 - val_mean_absolute_error: 0.0083\n","Epoch 460/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4555e-04 - mean_absolute_error: 0.0126\n","Epoch 460: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4539e-04 - mean_absolute_error: 0.0126 - val_loss: 1.6989e-04 - val_mean_absolute_error: 0.0086\n","Epoch 461/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3856e-04 - mean_absolute_error: 0.0125\n","Epoch 461: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4032e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4314e-04 - val_mean_absolute_error: 0.0079\n","Epoch 462/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7868e-04 - mean_absolute_error: 0.0132\n","Epoch 462: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.7923e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3593e-04 - val_mean_absolute_error: 0.0078\n","Epoch 463/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5649e-04 - mean_absolute_error: 0.0128\n","Epoch 463: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5806e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4625e-04 - val_mean_absolute_error: 0.0083\n","Epoch 464/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5846e-04 - mean_absolute_error: 0.0130\n","Epoch 464: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.5727e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6520e-04 - val_mean_absolute_error: 0.0082\n","Epoch 465/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5426e-04 - mean_absolute_error: 0.0126\n","Epoch 465: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5306e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3851e-04 - val_mean_absolute_error: 0.0081\n","Epoch 466/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5535e-04 - mean_absolute_error: 0.0129\n","Epoch 466: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5424e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3307e-04 - val_mean_absolute_error: 0.0082\n","Epoch 467/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5535e-04 - mean_absolute_error: 0.0126\n","Epoch 467: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5489e-04 - mean_absolute_error: 0.0126 - val_loss: 1.6234e-04 - val_mean_absolute_error: 0.0091\n","Epoch 468/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6586e-04 - mean_absolute_error: 0.0130\n","Epoch 468: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6506e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6091e-04 - val_mean_absolute_error: 0.0100\n","Epoch 469/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6625e-04 - mean_absolute_error: 0.0128\n","Epoch 469: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6589e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3344e-04 - val_mean_absolute_error: 0.0075\n","Epoch 470/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4768e-04 - mean_absolute_error: 0.0127\n","Epoch 470: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4727e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3743e-04 - val_mean_absolute_error: 0.0076\n","Epoch 471/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4450e-04 - mean_absolute_error: 0.0124\n","Epoch 471: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4576e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3456e-04 - val_mean_absolute_error: 0.0077\n","Epoch 472/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5841e-04 - mean_absolute_error: 0.0128\n","Epoch 472: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5803e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3706e-04 - val_mean_absolute_error: 0.0080\n","Epoch 473/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6886e-04 - mean_absolute_error: 0.0131\n","Epoch 473: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6898e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3526e-04 - val_mean_absolute_error: 0.0076\n","Epoch 474/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6431e-04 - mean_absolute_error: 0.0127\n","Epoch 474: val_loss improved from 0.00013 to 0.00013, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6289e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3126e-04 - val_mean_absolute_error: 0.0076\n","Epoch 475/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5916e-04 - mean_absolute_error: 0.0130\n","Epoch 475: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5764e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4028e-04 - val_mean_absolute_error: 0.0078\n","Epoch 476/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4543e-04 - mean_absolute_error: 0.0127\n","Epoch 476: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4524e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3495e-04 - val_mean_absolute_error: 0.0077\n","Epoch 477/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4180e-04 - mean_absolute_error: 0.0123\n","Epoch 477: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4182e-04 - mean_absolute_error: 0.0123 - val_loss: 1.3758e-04 - val_mean_absolute_error: 0.0083\n","Epoch 478/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6169e-04 - mean_absolute_error: 0.0129\n","Epoch 478: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6143e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3775e-04 - val_mean_absolute_error: 0.0076\n","Epoch 479/500\n","78/78 [==============================] - ETA: 0s - loss: 2.7731e-04 - mean_absolute_error: 0.0129\n","Epoch 479: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.7731e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3297e-04 - val_mean_absolute_error: 0.0075\n","Epoch 480/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3637e-04 - mean_absolute_error: 0.0124\n","Epoch 480: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.3745e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3596e-04 - val_mean_absolute_error: 0.0076\n","Epoch 481/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5738e-04 - mean_absolute_error: 0.0128\n","Epoch 481: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5892e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4131e-04 - val_mean_absolute_error: 0.0077\n","Epoch 482/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.7310e-04 - mean_absolute_error: 0.0130\n","Epoch 482: val_loss improved from 0.00013 to 0.00013, saving model to results/2022-04-09_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","78/78 [==============================] - 3s 40ms/step - loss: 2.7273e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3092e-04 - val_mean_absolute_error: 0.0075\n","Epoch 483/500\n","78/78 [==============================] - ETA: 0s - loss: 2.6082e-04 - mean_absolute_error: 0.0128\n","Epoch 483: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6082e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3658e-04 - val_mean_absolute_error: 0.0079\n","Epoch 484/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3762e-04 - mean_absolute_error: 0.0124\n","Epoch 484: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.3627e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3327e-04 - val_mean_absolute_error: 0.0075\n","Epoch 485/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4183e-04 - mean_absolute_error: 0.0126\n","Epoch 485: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4088e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3516e-04 - val_mean_absolute_error: 0.0076\n","Epoch 486/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4633e-04 - mean_absolute_error: 0.0126\n","Epoch 486: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4597e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4588e-04 - val_mean_absolute_error: 0.0089\n","Epoch 487/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6156e-04 - mean_absolute_error: 0.0127\n","Epoch 487: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.6074e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4025e-04 - val_mean_absolute_error: 0.0079\n","Epoch 488/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5166e-04 - mean_absolute_error: 0.0125\n","Epoch 488: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5161e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3505e-04 - val_mean_absolute_error: 0.0079\n","Epoch 489/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5378e-04 - mean_absolute_error: 0.0127\n","Epoch 489: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5271e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4323e-04 - val_mean_absolute_error: 0.0083\n","Epoch 490/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5337e-04 - mean_absolute_error: 0.0127\n","Epoch 490: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5258e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4765e-04 - val_mean_absolute_error: 0.0084\n","Epoch 491/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5754e-04 - mean_absolute_error: 0.0129\n","Epoch 491: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5634e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3699e-04 - val_mean_absolute_error: 0.0079\n","Epoch 492/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.3568e-04 - mean_absolute_error: 0.0123\n","Epoch 492: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.3476e-04 - mean_absolute_error: 0.0123 - val_loss: 1.4193e-04 - val_mean_absolute_error: 0.0091\n","Epoch 493/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5641e-04 - mean_absolute_error: 0.0127\n","Epoch 493: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.5689e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3522e-04 - val_mean_absolute_error: 0.0082\n","Epoch 494/500\n","78/78 [==============================] - ETA: 0s - loss: 2.4048e-04 - mean_absolute_error: 0.0126\n","Epoch 494: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 41ms/step - loss: 2.4048e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5341e-04 - val_mean_absolute_error: 0.0090\n","Epoch 495/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4522e-04 - mean_absolute_error: 0.0125\n","Epoch 495: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4530e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3159e-04 - val_mean_absolute_error: 0.0074\n","Epoch 496/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4916e-04 - mean_absolute_error: 0.0125\n","Epoch 496: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 40ms/step - loss: 2.4808e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3846e-04 - val_mean_absolute_error: 0.0084\n","Epoch 497/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5667e-04 - mean_absolute_error: 0.0128\n","Epoch 497: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5799e-04 - mean_absolute_error: 0.0128 - val_loss: 1.7287e-04 - val_mean_absolute_error: 0.0094\n","Epoch 498/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.5818e-04 - mean_absolute_error: 0.0128\n","Epoch 498: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.5985e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3559e-04 - val_mean_absolute_error: 0.0076\n","Epoch 499/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.6708e-04 - mean_absolute_error: 0.0130\n","Epoch 499: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.6684e-04 - mean_absolute_error: 0.0130 - val_loss: 1.3356e-04 - val_mean_absolute_error: 0.0076\n","Epoch 500/500\n","77/78 [============================>.] - ETA: 0s - loss: 2.4305e-04 - mean_absolute_error: 0.0126\n","Epoch 500: val_loss did not improve from 0.00013\n","78/78 [==============================] - 3s 39ms/step - loss: 2.4291e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3282e-04 - val_mean_absolute_error: 0.0079\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_graph(test_df):\n","    \n","    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n","    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n","    plt.xlabel(\"Days\")\n","    plt.ylabel(\"Price\")\n","    plt.legend([\"Actual Price\", \"Predicted Price\"])\n","    plt.show()"],"metadata":{"id":"UEJ4iar_anS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_final_df(model, data):\n","    \n","    # if predicted future price is higher than the current, \n","    # then calculate the true future price minus the current price, to get the buy profit\n","    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n","    # if the predicted future price is lower than the current price,\n","    # then subtract the true future price from the current price\n","    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n","    X_test = data[\"X_test\"]\n","    y_test = data[\"y_test\"]\n","    # perform prediction and get prices\n","    y_pred = model.predict(X_test)\n","    if SCALE:\n","        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n","        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n","    test_df = data[\"test_df\"]\n","    # add predicted future prices to the dataframe\n","    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n","    # add true future prices to the dataframe\n","    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n","    # sort the dataframe by date\n","    test_df.sort_index(inplace=True)\n","    final_df = test_df\n","    # add the buy profit column\n","    final_df[\"buy_profit\"] = list(map(buy_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    # add the sell profit column\n","    final_df[\"sell_profit\"] = list(map(sell_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    return final_df"],"metadata":{"id":"FOhJClZXbYBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model, data):\n","    # retrieve the last sequence from data\n","    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n","    # expand dimension\n","    last_sequence = np.expand_dims(last_sequence, axis=0)\n","    # get the prediction (scaled from 0 to 1)\n","    prediction = model.predict(last_sequence)\n","    # get the price (by inverting the scaling)\n","    if SCALE:\n","        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n","    else:\n","        predicted_price = prediction[0][0]\n","    return predicted_price"],"metadata":{"id":"yzXqHJGQbZgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load optimal model weights from results folder\n","model_path = os.path.join(\"results\", model_name) + \".h5\"\n","model.load_weights(model_path)"],"metadata":{"id":"1__DYuJ2baj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate the model\n","loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n","# calculate the mean absolute error (inverse scaling)\n","if SCALE:\n","    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n","else:\n","    mean_absolute_error = mae"],"metadata":{"id":"5GDLKXyWbbhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the final dataframe for the testing set\n","final_df = get_final_df(model, data)"],"metadata":{"id":"_Gg8qmsrbcfy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict the future price\n","future_price = predict(model, data)"],"metadata":{"id":"6sQfrE3EbdWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we calculate the accuracy by counting the number of positive profits\n","accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n","# calculating total buy & sell profit\n","total_buy_profit  = final_df[\"buy_profit\"].sum()\n","total_sell_profit = final_df[\"sell_profit\"].sum()\n","# total profit by adding sell & buy together\n","total_profit = total_buy_profit + total_sell_profit\n","# dividing total profit by number of testing samples (number of trades)\n","profit_per_trade = total_profit / len(final_df)"],"metadata":{"id":"AFbCVRo3beua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# printing metrics\n","print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n","print(f\"{LOSS} loss:\", loss)\n","print(\"Mean Absolute Error:\", mean_absolute_error)\n","print(\"Accuracy score:\", accuracy_score)\n","print(\"Total buy profit:\", total_buy_profit)\n","print(\"Total sell profit:\", total_sell_profit)\n","print(\"Total profit:\", total_profit)\n","print(\"Profit per trade:\", profit_per_trade)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-XTrlBubwW0","executionInfo":{"status":"ok","timestamp":1649488551641,"user_tz":-330,"elapsed":11,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"d4e5a4f5-1f49-48f4-a69b-234c269b05e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Future price after 15 days is 3239.57$\n","huber_loss loss: 0.00013091923028696328\n","Mean Absolute Error: 29.436946274117908\n","Accuracy score: 0.6099919419822724\n","Total buy profit: 15296.26982498169\n","Total sell profit: 5352.079315185547\n","Total profit: 20648.349140167236\n","Profit per trade: 16.63847634179471\n"]}]},{"cell_type":"code","source":["# plot true/pred prices graph\n","plot_graph(final_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"2otpryPdbysv","executionInfo":{"status":"ok","timestamp":1649488551642,"user_tz":-330,"elapsed":11,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"b460131b-3202-4e10-9931-7117f3de4529"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["final_df.head(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"DdvFYdV_cAYi","executionInfo":{"status":"ok","timestamp":1649488551642,"user_tz":-330,"elapsed":10,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"880056c1-4d0e-4232-d0b4-a4d30320ade0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                open      high       low     close  adjclose    volume ticker  \\\n","1997-08-07  2.250000  2.260417  2.125000  2.177083  2.177083   2034000   AMZN   \n","1997-08-18  2.052083  2.052083  1.968750  2.041667  2.041667   1784400   AMZN   \n","1997-08-21  2.135417  2.171875  2.072917  2.114583  2.114583    624000   AMZN   \n","1997-09-05  2.583333  2.666667  2.458333  2.500000  2.500000   1908000   AMZN   \n","1997-09-08  2.531250  3.020833  2.500000  3.000000  3.000000   5648400   AMZN   \n","1997-09-10  3.312500  3.328125  3.125000  3.302083  3.302083   3866400   AMZN   \n","1997-09-12  3.187500  3.697917  3.156250  3.687500  3.687500   3333600   AMZN   \n","1997-09-15  3.666667  3.677083  3.052083  3.093750  3.093750   5583600   AMZN   \n","1997-09-17  3.458333  3.500000  3.333333  3.406250  3.406250   2607600   AMZN   \n","1997-09-29  4.145833  4.187500  3.958333  4.041667  4.041667   2371200   AMZN   \n","1997-10-06  4.000000  4.125000  3.942708  4.125000  4.125000   2028000   AMZN   \n","1997-10-17  3.614583  3.656250  3.520833  3.625000  3.625000   2534400   AMZN   \n","1997-10-20  3.677083  3.875000  3.666667  3.822917  3.822917   4912800   AMZN   \n","1997-10-21  3.958333  4.437500  3.854167  4.427083  4.427083  12096000   AMZN   \n","1997-10-28  3.916667  5.000000  3.875000  4.947917  4.947917  11719200   AMZN   \n","1997-10-31  5.364583  5.458333  4.968750  5.083333  5.083333   5026800   AMZN   \n","1997-11-05  4.979167  5.119792  4.875000  4.875000  4.875000   3093600   AMZN   \n","1997-11-07  4.416667  4.640625  4.385417  4.479167  4.479167   2626800   AMZN   \n","1997-11-17  4.229167  4.541667  4.218750  4.375000  4.375000   7394400   AMZN   \n","1997-11-18  4.375000  4.479167  4.343750  4.416667  4.416667   1866000   AMZN   \n","\n","            adjclose_15  true_adjclose_15  buy_profit  sell_profit  \n","1997-08-07     7.575833          2.375000    0.197917          0.0  \n","1997-08-18     7.933390          3.239583    1.197916          0.0  \n","1997-08-21     7.976799          3.687500    1.572917          0.0  \n","1997-09-05     8.073066          4.166667    1.666667          0.0  \n","1997-09-08     7.714454          4.041667    1.041667          0.0  \n","1997-09-10     7.507024          4.020833    0.718750          0.0  \n","1997-09-12     7.399973          4.015625    0.328125          0.0  \n","1997-09-15     7.138963          4.125000    1.031250          0.0  \n","1997-09-17     8.109583          4.005208    0.598958          0.0  \n","1997-09-29     8.973320          3.822917   -0.218750          0.0  \n","1997-10-06    10.912560          4.270833    0.145833          0.0  \n","1997-10-17     9.330932          4.479167    0.854167          0.0  \n","1997-10-20     9.268180          4.208333    0.385416          0.0  \n","1997-10-21     9.156295          3.947917   -0.479166          0.0  \n","1997-10-28     7.209051          4.416667   -0.531250          0.0  \n","1997-10-31     8.548121          4.489583   -0.593750          0.0  \n","1997-11-05    11.018221          4.260417   -0.614583          0.0  \n","1997-11-07    11.294961          4.270833   -0.208334          0.0  \n","1997-11-17     9.444763          4.687500    0.312500          0.0  \n","1997-11-18     9.629238          4.510417    0.093750          0.0  "],"text/html":["\n","  <div id=\"df-740f71b9-7fd4-41b6-a3b0-348b9c2a5edb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>adjclose</th>\n","      <th>volume</th>\n","      <th>ticker</th>\n","      <th>adjclose_15</th>\n","      <th>true_adjclose_15</th>\n","      <th>buy_profit</th>\n","      <th>sell_profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1997-08-07</th>\n","      <td>2.250000</td>\n","      <td>2.260417</td>\n","      <td>2.125000</td>\n","      <td>2.177083</td>\n","      <td>2.177083</td>\n","      <td>2034000</td>\n","      <td>AMZN</td>\n","      <td>7.575833</td>\n","      <td>2.375000</td>\n","      <td>0.197917</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-08-18</th>\n","      <td>2.052083</td>\n","      <td>2.052083</td>\n","      <td>1.968750</td>\n","      <td>2.041667</td>\n","      <td>2.041667</td>\n","      <td>1784400</td>\n","      <td>AMZN</td>\n","      <td>7.933390</td>\n","      <td>3.239583</td>\n","      <td>1.197916</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-08-21</th>\n","      <td>2.135417</td>\n","      <td>2.171875</td>\n","      <td>2.072917</td>\n","      <td>2.114583</td>\n","      <td>2.114583</td>\n","      <td>624000</td>\n","      <td>AMZN</td>\n","      <td>7.976799</td>\n","      <td>3.687500</td>\n","      <td>1.572917</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-05</th>\n","      <td>2.583333</td>\n","      <td>2.666667</td>\n","      <td>2.458333</td>\n","      <td>2.500000</td>\n","      <td>2.500000</td>\n","      <td>1908000</td>\n","      <td>AMZN</td>\n","      <td>8.073066</td>\n","      <td>4.166667</td>\n","      <td>1.666667</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-08</th>\n","      <td>2.531250</td>\n","      <td>3.020833</td>\n","      <td>2.500000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>5648400</td>\n","      <td>AMZN</td>\n","      <td>7.714454</td>\n","      <td>4.041667</td>\n","      <td>1.041667</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-10</th>\n","      <td>3.312500</td>\n","      <td>3.328125</td>\n","      <td>3.125000</td>\n","      <td>3.302083</td>\n","      <td>3.302083</td>\n","      <td>3866400</td>\n","      <td>AMZN</td>\n","      <td>7.507024</td>\n","      <td>4.020833</td>\n","      <td>0.718750</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-12</th>\n","      <td>3.187500</td>\n","      <td>3.697917</td>\n","      <td>3.156250</td>\n","      <td>3.687500</td>\n","      <td>3.687500</td>\n","      <td>3333600</td>\n","      <td>AMZN</td>\n","      <td>7.399973</td>\n","      <td>4.015625</td>\n","      <td>0.328125</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-15</th>\n","      <td>3.666667</td>\n","      <td>3.677083</td>\n","      <td>3.052083</td>\n","      <td>3.093750</td>\n","      <td>3.093750</td>\n","      <td>5583600</td>\n","      <td>AMZN</td>\n","      <td>7.138963</td>\n","      <td>4.125000</td>\n","      <td>1.031250</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-17</th>\n","      <td>3.458333</td>\n","      <td>3.500000</td>\n","      <td>3.333333</td>\n","      <td>3.406250</td>\n","      <td>3.406250</td>\n","      <td>2607600</td>\n","      <td>AMZN</td>\n","      <td>8.109583</td>\n","      <td>4.005208</td>\n","      <td>0.598958</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-09-29</th>\n","      <td>4.145833</td>\n","      <td>4.187500</td>\n","      <td>3.958333</td>\n","      <td>4.041667</td>\n","      <td>4.041667</td>\n","      <td>2371200</td>\n","      <td>AMZN</td>\n","      <td>8.973320</td>\n","      <td>3.822917</td>\n","      <td>-0.218750</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-06</th>\n","      <td>4.000000</td>\n","      <td>4.125000</td>\n","      <td>3.942708</td>\n","      <td>4.125000</td>\n","      <td>4.125000</td>\n","      <td>2028000</td>\n","      <td>AMZN</td>\n","      <td>10.912560</td>\n","      <td>4.270833</td>\n","      <td>0.145833</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-17</th>\n","      <td>3.614583</td>\n","      <td>3.656250</td>\n","      <td>3.520833</td>\n","      <td>3.625000</td>\n","      <td>3.625000</td>\n","      <td>2534400</td>\n","      <td>AMZN</td>\n","      <td>9.330932</td>\n","      <td>4.479167</td>\n","      <td>0.854167</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-20</th>\n","      <td>3.677083</td>\n","      <td>3.875000</td>\n","      <td>3.666667</td>\n","      <td>3.822917</td>\n","      <td>3.822917</td>\n","      <td>4912800</td>\n","      <td>AMZN</td>\n","      <td>9.268180</td>\n","      <td>4.208333</td>\n","      <td>0.385416</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-21</th>\n","      <td>3.958333</td>\n","      <td>4.437500</td>\n","      <td>3.854167</td>\n","      <td>4.427083</td>\n","      <td>4.427083</td>\n","      <td>12096000</td>\n","      <td>AMZN</td>\n","      <td>9.156295</td>\n","      <td>3.947917</td>\n","      <td>-0.479166</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-28</th>\n","      <td>3.916667</td>\n","      <td>5.000000</td>\n","      <td>3.875000</td>\n","      <td>4.947917</td>\n","      <td>4.947917</td>\n","      <td>11719200</td>\n","      <td>AMZN</td>\n","      <td>7.209051</td>\n","      <td>4.416667</td>\n","      <td>-0.531250</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-10-31</th>\n","      <td>5.364583</td>\n","      <td>5.458333</td>\n","      <td>4.968750</td>\n","      <td>5.083333</td>\n","      <td>5.083333</td>\n","      <td>5026800</td>\n","      <td>AMZN</td>\n","      <td>8.548121</td>\n","      <td>4.489583</td>\n","      <td>-0.593750</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-11-05</th>\n","      <td>4.979167</td>\n","      <td>5.119792</td>\n","      <td>4.875000</td>\n","      <td>4.875000</td>\n","      <td>4.875000</td>\n","      <td>3093600</td>\n","      <td>AMZN</td>\n","      <td>11.018221</td>\n","      <td>4.260417</td>\n","      <td>-0.614583</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-11-07</th>\n","      <td>4.416667</td>\n","      <td>4.640625</td>\n","      <td>4.385417</td>\n","      <td>4.479167</td>\n","      <td>4.479167</td>\n","      <td>2626800</td>\n","      <td>AMZN</td>\n","      <td>11.294961</td>\n","      <td>4.270833</td>\n","      <td>-0.208334</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-11-17</th>\n","      <td>4.229167</td>\n","      <td>4.541667</td>\n","      <td>4.218750</td>\n","      <td>4.375000</td>\n","      <td>4.375000</td>\n","      <td>7394400</td>\n","      <td>AMZN</td>\n","      <td>9.444763</td>\n","      <td>4.687500</td>\n","      <td>0.312500</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997-11-18</th>\n","      <td>4.375000</td>\n","      <td>4.479167</td>\n","      <td>4.343750</td>\n","      <td>4.416667</td>\n","      <td>4.416667</td>\n","      <td>1866000</td>\n","      <td>AMZN</td>\n","      <td>9.629238</td>\n","      <td>4.510417</td>\n","      <td>0.093750</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-740f71b9-7fd4-41b6-a3b0-348b9c2a5edb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-740f71b9-7fd4-41b6-a3b0-348b9c2a5edb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-740f71b9-7fd4-41b6-a3b0-348b9c2a5edb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["final_df.tail(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"pASL9MRbcBYj","executionInfo":{"status":"ok","timestamp":1649488551643,"user_tz":-330,"elapsed":10,"user":{"displayName":"Home Service Provider SGP","userId":"04255449144539044040"}},"outputId":"55d11836-bbf3-4fc4-e083-5c44f2cfd98b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   open         high          low        close     adjclose  \\\n","2021-10-27  3388.000000  3437.000000  3371.449951  3392.489990  3392.489990   \n","2021-11-01  3361.800049  3375.860107  3292.020020  3318.110107  3318.110107   \n","2021-11-03  3309.000000  3394.919922  3297.520020  3384.000000  3384.000000   \n","2021-11-04  3370.000000  3498.629883  3365.000000  3477.000000  3477.000000   \n","2021-11-19  3712.689941  3762.149902  3675.719971  3676.570068  3676.570068   \n","2021-11-23  3585.040039  3621.050049  3527.709961  3580.040039  3580.040039   \n","2021-12-23  3408.560059  3439.500000  3403.000000  3421.370117  3421.370117   \n","2021-12-28  3403.649902  3443.520020  3382.709961  3413.219971  3413.219971   \n","2022-01-05  3337.659912  3342.530029  3287.139893  3287.139893  3287.139893   \n","2022-01-10  3211.709961  3233.229980  3126.090088  3229.719971  3229.719971   \n","2022-01-19  3175.239990  3185.000000  3125.000000  3125.979980  3125.979980   \n","2022-01-20  3135.320068  3160.000000  3027.020020  3033.350098  3033.350098   \n","2022-01-26  2895.000000  2903.699951  2746.370117  2777.449951  2777.449951   \n","2022-01-27  2816.000000  2884.870117  2787.000000  2792.750000  2792.750000   \n","2022-02-02  3101.010010  3101.500000  2977.270020  3012.250000  3012.250000   \n","2022-02-09  3257.469971  3276.689941  3205.000000  3223.790039  3223.790039   \n","2022-02-25  3011.000000  3079.800049  2984.270020  3075.770020  3075.770020   \n","2022-02-28  3048.500000  3089.000000  3017.000000  3071.260010  3071.260010   \n","2022-03-04  2943.179932  2957.000000  2876.139893  2912.820068  2912.820068   \n","2022-03-14  2919.620117  2949.000000  2817.679932  2837.060059  2837.060059   \n","\n","             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n","2021-10-27  2702200   AMZN  3303.101807       3549.000000    0.000000   \n","2021-11-01  3608900   AMZN  3294.849609       3572.570068    0.000000   \n","2021-11-03  3397200   AMZN  3294.323486       3580.409912    0.000000   \n","2021-11-04  5353000   AMZN  3301.574951       3504.560059    0.000000   \n","2021-11-19  4936700   AMZN  3351.601074       3391.350098    0.000000   \n","2021-11-23  3690200   AMZN  3346.293945       3466.300049    0.000000   \n","2021-12-23  1839400   AMZN  3316.677490       3242.760010    0.000000   \n","2021-12-28  2731900   AMZN  3315.679932       3125.979980    0.000000   \n","2022-01-05  3215100   AMZN  3299.233887       2792.750000 -494.389893   \n","2022-01-10  4389900   AMZN  3276.110352       3023.870117 -205.849854   \n","2022-01-19  2662100   AMZN  3259.319336       3223.790039   97.810059   \n","2022-01-20  3598700   AMZN  3242.592285       3180.070068  146.719971   \n","2022-01-26  4780100   AMZN  3147.631592       3162.010010  384.560059   \n","2022-01-27  3875800   AMZN  3141.177002       3093.050049  300.300049   \n","2022-02-02  4366500   AMZN  3173.056152       3027.159912   14.909912   \n","2022-02-09  3439300   AMZN  3219.087891       2957.969971    0.000000   \n","2022-02-25  3119800   AMZN  3180.961182       3225.010010  149.239990   \n","2022-02-28  2884200   AMZN  3186.263184       3229.830078  158.570068   \n","2022-03-04  3046700   AMZN  3167.418213       3295.469971  382.649902   \n","2022-03-14  3704300   AMZN  3127.957764       3366.929932  529.869873   \n","\n","            sell_profit  \n","2021-10-27  -156.510010  \n","2021-11-01  -254.459961  \n","2021-11-03  -196.409912  \n","2021-11-04   -27.560059  \n","2021-11-19   285.219971  \n","2021-11-23   113.739990  \n","2021-12-23   178.610107  \n","2021-12-28   287.239990  \n","2022-01-05     0.000000  \n","2022-01-10     0.000000  \n","2022-01-19     0.000000  \n","2022-01-20     0.000000  \n","2022-01-26     0.000000  \n","2022-01-27     0.000000  \n","2022-02-02     0.000000  \n","2022-02-09   265.820068  \n","2022-02-25     0.000000  \n","2022-02-28     0.000000  \n","2022-03-04     0.000000  \n","2022-03-14     0.000000  "],"text/html":["\n","  <div id=\"df-c8d11053-7f0c-433e-b8dd-9b3ffd396445\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>adjclose</th>\n","      <th>volume</th>\n","      <th>ticker</th>\n","      <th>adjclose_15</th>\n","      <th>true_adjclose_15</th>\n","      <th>buy_profit</th>\n","      <th>sell_profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-10-27</th>\n","      <td>3388.000000</td>\n","      <td>3437.000000</td>\n","      <td>3371.449951</td>\n","      <td>3392.489990</td>\n","      <td>3392.489990</td>\n","      <td>2702200</td>\n","      <td>AMZN</td>\n","      <td>3303.101807</td>\n","      <td>3549.000000</td>\n","      <td>0.000000</td>\n","      <td>-156.510010</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-01</th>\n","      <td>3361.800049</td>\n","      <td>3375.860107</td>\n","      <td>3292.020020</td>\n","      <td>3318.110107</td>\n","      <td>3318.110107</td>\n","      <td>3608900</td>\n","      <td>AMZN</td>\n","      <td>3294.849609</td>\n","      <td>3572.570068</td>\n","      <td>0.000000</td>\n","      <td>-254.459961</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-03</th>\n","      <td>3309.000000</td>\n","      <td>3394.919922</td>\n","      <td>3297.520020</td>\n","      <td>3384.000000</td>\n","      <td>3384.000000</td>\n","      <td>3397200</td>\n","      <td>AMZN</td>\n","      <td>3294.323486</td>\n","      <td>3580.409912</td>\n","      <td>0.000000</td>\n","      <td>-196.409912</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-04</th>\n","      <td>3370.000000</td>\n","      <td>3498.629883</td>\n","      <td>3365.000000</td>\n","      <td>3477.000000</td>\n","      <td>3477.000000</td>\n","      <td>5353000</td>\n","      <td>AMZN</td>\n","      <td>3301.574951</td>\n","      <td>3504.560059</td>\n","      <td>0.000000</td>\n","      <td>-27.560059</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-19</th>\n","      <td>3712.689941</td>\n","      <td>3762.149902</td>\n","      <td>3675.719971</td>\n","      <td>3676.570068</td>\n","      <td>3676.570068</td>\n","      <td>4936700</td>\n","      <td>AMZN</td>\n","      <td>3351.601074</td>\n","      <td>3391.350098</td>\n","      <td>0.000000</td>\n","      <td>285.219971</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-23</th>\n","      <td>3585.040039</td>\n","      <td>3621.050049</td>\n","      <td>3527.709961</td>\n","      <td>3580.040039</td>\n","      <td>3580.040039</td>\n","      <td>3690200</td>\n","      <td>AMZN</td>\n","      <td>3346.293945</td>\n","      <td>3466.300049</td>\n","      <td>0.000000</td>\n","      <td>113.739990</td>\n","    </tr>\n","    <tr>\n","      <th>2021-12-23</th>\n","      <td>3408.560059</td>\n","      <td>3439.500000</td>\n","      <td>3403.000000</td>\n","      <td>3421.370117</td>\n","      <td>3421.370117</td>\n","      <td>1839400</td>\n","      <td>AMZN</td>\n","      <td>3316.677490</td>\n","      <td>3242.760010</td>\n","      <td>0.000000</td>\n","      <td>178.610107</td>\n","    </tr>\n","    <tr>\n","      <th>2021-12-28</th>\n","      <td>3403.649902</td>\n","      <td>3443.520020</td>\n","      <td>3382.709961</td>\n","      <td>3413.219971</td>\n","      <td>3413.219971</td>\n","      <td>2731900</td>\n","      <td>AMZN</td>\n","      <td>3315.679932</td>\n","      <td>3125.979980</td>\n","      <td>0.000000</td>\n","      <td>287.239990</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-05</th>\n","      <td>3337.659912</td>\n","      <td>3342.530029</td>\n","      <td>3287.139893</td>\n","      <td>3287.139893</td>\n","      <td>3287.139893</td>\n","      <td>3215100</td>\n","      <td>AMZN</td>\n","      <td>3299.233887</td>\n","      <td>2792.750000</td>\n","      <td>-494.389893</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-10</th>\n","      <td>3211.709961</td>\n","      <td>3233.229980</td>\n","      <td>3126.090088</td>\n","      <td>3229.719971</td>\n","      <td>3229.719971</td>\n","      <td>4389900</td>\n","      <td>AMZN</td>\n","      <td>3276.110352</td>\n","      <td>3023.870117</td>\n","      <td>-205.849854</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-19</th>\n","      <td>3175.239990</td>\n","      <td>3185.000000</td>\n","      <td>3125.000000</td>\n","      <td>3125.979980</td>\n","      <td>3125.979980</td>\n","      <td>2662100</td>\n","      <td>AMZN</td>\n","      <td>3259.319336</td>\n","      <td>3223.790039</td>\n","      <td>97.810059</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-20</th>\n","      <td>3135.320068</td>\n","      <td>3160.000000</td>\n","      <td>3027.020020</td>\n","      <td>3033.350098</td>\n","      <td>3033.350098</td>\n","      <td>3598700</td>\n","      <td>AMZN</td>\n","      <td>3242.592285</td>\n","      <td>3180.070068</td>\n","      <td>146.719971</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-26</th>\n","      <td>2895.000000</td>\n","      <td>2903.699951</td>\n","      <td>2746.370117</td>\n","      <td>2777.449951</td>\n","      <td>2777.449951</td>\n","      <td>4780100</td>\n","      <td>AMZN</td>\n","      <td>3147.631592</td>\n","      <td>3162.010010</td>\n","      <td>384.560059</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-27</th>\n","      <td>2816.000000</td>\n","      <td>2884.870117</td>\n","      <td>2787.000000</td>\n","      <td>2792.750000</td>\n","      <td>2792.750000</td>\n","      <td>3875800</td>\n","      <td>AMZN</td>\n","      <td>3141.177002</td>\n","      <td>3093.050049</td>\n","      <td>300.300049</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-02</th>\n","      <td>3101.010010</td>\n","      <td>3101.500000</td>\n","      <td>2977.270020</td>\n","      <td>3012.250000</td>\n","      <td>3012.250000</td>\n","      <td>4366500</td>\n","      <td>AMZN</td>\n","      <td>3173.056152</td>\n","      <td>3027.159912</td>\n","      <td>14.909912</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-09</th>\n","      <td>3257.469971</td>\n","      <td>3276.689941</td>\n","      <td>3205.000000</td>\n","      <td>3223.790039</td>\n","      <td>3223.790039</td>\n","      <td>3439300</td>\n","      <td>AMZN</td>\n","      <td>3219.087891</td>\n","      <td>2957.969971</td>\n","      <td>0.000000</td>\n","      <td>265.820068</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-25</th>\n","      <td>3011.000000</td>\n","      <td>3079.800049</td>\n","      <td>2984.270020</td>\n","      <td>3075.770020</td>\n","      <td>3075.770020</td>\n","      <td>3119800</td>\n","      <td>AMZN</td>\n","      <td>3180.961182</td>\n","      <td>3225.010010</td>\n","      <td>149.239990</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-28</th>\n","      <td>3048.500000</td>\n","      <td>3089.000000</td>\n","      <td>3017.000000</td>\n","      <td>3071.260010</td>\n","      <td>3071.260010</td>\n","      <td>2884200</td>\n","      <td>AMZN</td>\n","      <td>3186.263184</td>\n","      <td>3229.830078</td>\n","      <td>158.570068</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-03-04</th>\n","      <td>2943.179932</td>\n","      <td>2957.000000</td>\n","      <td>2876.139893</td>\n","      <td>2912.820068</td>\n","      <td>2912.820068</td>\n","      <td>3046700</td>\n","      <td>AMZN</td>\n","      <td>3167.418213</td>\n","      <td>3295.469971</td>\n","      <td>382.649902</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2022-03-14</th>\n","      <td>2919.620117</td>\n","      <td>2949.000000</td>\n","      <td>2817.679932</td>\n","      <td>2837.060059</td>\n","      <td>2837.060059</td>\n","      <td>3704300</td>\n","      <td>AMZN</td>\n","      <td>3127.957764</td>\n","      <td>3366.929932</td>\n","      <td>529.869873</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d11053-7f0c-433e-b8dd-9b3ffd396445')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c8d11053-7f0c-433e-b8dd-9b3ffd396445 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c8d11053-7f0c-433e-b8dd-9b3ffd396445');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# save the final dataframe to csv-results folder\n","csv_results_folder = \"csv-results\"\n","if not os.path.isdir(csv_results_folder):\n","    os.mkdir(csv_results_folder)\n","csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n","final_df.to_csv(csv_filename)"],"metadata":{"id":"6TK6xMexcCey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"TqxqXlbRcDZb"},"execution_count":null,"outputs":[]}]}